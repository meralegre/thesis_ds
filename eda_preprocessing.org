
#+TITLE: EDA & Preprocessing of Musical Corpus
#+AUTHOR: Maria Gonzalez Alegre
#+DATE: 2025-12-31

#+PROPERTY: header-args:python :results output :exports results :eval yes

* Introduction
* Conclusion
* Manual Preprocessing
** Imports

#+begin_src python :results silent
import pandas as pd
import numpy as np

import os
import re
import zipfile
import pathlib
import random
from pathlib import Path
from typing import List, Optional
from dataclasses import dataclass
from collections import Counter
from music21 import pitch

import matplotlib
# matplotlib.use("Agg")
import matplotlib.pyplot as plt

import seaborn as sns
sns.set_theme(
    style="whitegrid",
    context="talk",
)
#+end_src

** Kern syntax

In the Humdrum syntax, columns of data are called SPINES. SPINES of information may change
position within a file; they may disappear, or split into several columns, for example.

Based on the information found in the Github repo with the Essen files [cite], the music files contain
several indicators that need to be taken into account:

*** INTERPRETATIONS

  Labels that indicate the type of information being represented in each Spine. They are
  represented as two asterisks (**). We also have *SPINE-PATH TERMINATORS*, they indicate the end
  of their respective spine, represented as *-

*** TANDEM INTERPRETATIONS

  Tandem interpretations are identified by a single leading asterisk (*).
  Tandem interpretations encode additional or supplementary information, for example the names
  of the voices

*** COMMENTS

In any representation, some information may best be conveyed as
  COMMENTS rather than as part of the encoded data. In Humdrum formats they are expressed as
  exclamation marks:
  - *GLOBAL COMMENTS*: they begin with two exclamation marks
  - *LOCAL COMMENTS*: they begin with one exclamation mark
  - *NULL LOCAL COMMENTS*: exclamation marks with no text

*** PITCH

Enconded through a scheme of upper and lower case letters:
  - c      middle C (i.e. C4)
  - cc     C an octave higher than middle C (C5)
  - C      C an octave lower than middle C (C3)
  - CC     C two octaves lower than middle C (C2)
  - B      B below middle C (B3)
  - b      B a major seventh above middle C (B4)
  - d#     D-sharp above middle C (D#4)
  - d##    D double-sharp above middle C
  - d###   D tiple-sharp above middle C
  - e-     E-flat above middle C (enharmonically equivalent to d##)
  - BB--   B double-flat; augmented ninth below middle C
  - cn     C natural, middle C

  Sharps, flats, and naturals are mutually exclusive in **kern, so tokens such as "cc#n" and
  "GG-#" are illegal. Something to take into account when cleaning the data, in case some errors
  are present.

*** SLURS, TIES, PHRASES

  - *Phrases*: indicated by {}
  - *Slurs*: indicated by () --> ligadura entre notas distintas
  - *Ties*: indicated by [] --> ligadura entre misma nota

  They can be nested and elided (the overlapping of phrases, where the last note or chord
  of one phrase serves simultaneously as the first note or chord of the next)

*** ORNAMENTS

  - "T" and "t": whole-tone and semitone TRILLS
  - "M" and "m": whole-tone and semitone MORDENTS
  - "W" and "w": whole-tone and semitone INVERTED MORDENTS
  - "S":  a TURN
  - dollar sign ("$"): an inverted (or Wagnerian) TURN
  - "R":  When a concluding turn is appended to the end of an ornament, "R" is
    added to the ornament signifier (as in "tR" and "TR").
  - ":" (multi-note) ARPEGGIATION
  - "0": presence of ornaments OTHER than trills, mordents, inverted mordents, and turns.

*** ARTICULATION MARKS

  - (') for STACCATO
  - double-quote (") for PIZZICATO
  - greve (`) for ATTACCA
  - tilde (~) for TENUTO
  - caret (^) for all note-related accents (including < and >)

*** UP & DOWN BOWS

  - up-bow (v) and down-bow (u)

*** STEMS (plica)

  - "/": Up-stem
  - "\": Down-stem

*** DURATIONS

0       breve duration (redonda)
  1       whole duration
  2       half duration
  4       quarter duration
  8       eighth duration
  16      sixteenth duration
  32      thirty-second duration
  64      sixty-fourth duration

  *Dotted notes*:
    2.	dotted half duration
    8..	doubly-dotted eighth duration

  The semicolon (;) denotes a pause.

*** GRACE NOTES & GROUPETTOS

  - *ACCIACCATURAS*: "q", e.g "G#q"
  - *GROUPETTOS*: "Q", e.g minature sixteenth-note middle C would be encoded as "16cQ"
  - *APPOGGIATURAS*: The appoggiatura note itself is designated by the upper-case letter "P", whereas
    the subsequent note (whose notated duration has been shorted) is designated by the
    lower-case letter "p".

*** BEAMING

  - beginning and ends of beams are signified by the upper-case letters
    "L" and "J" respectively
  - Partial beams may extend to the right (K) or left (k)
  - each beam is designated by its own L-J pair, e.g:
    16..LL
    64JJkk
 
*** BARLINES

   0-9	measure numbers
   a-z	alternate measures
   ;	pause
   =	barline
   ==	double barline
   |	normal width visual rendering
   !	heavy width visual rendering
   '	partial barline (from second to fourth line)
   `	partial barline (short stroke at top of staff)
   -	invisible barline
   :	repeat sign

**** Examples
     =	        unnumbered barline
     =29 	the beginning of measure 29
     =29; 	the beginning of measure 29 with pause
     =29a	first occurrence of measure 29
     =29c	third occurrence of measure 29
     =29c;	third occurrence of measure 29 with pause
     ==	        double barline
     ==;	double barline with pause
     =|	        unnumbered barline, normal line width
     =!	        unnumbered barline, heavy line width
     ==|!	double barline, normal line followed by heavy line
     =29|	beginning of measure 29, normal line width
     =:|:	barline with left and right repeats, normal line width
     =:||:	barline with left and right repeats, two normal-width lines
     ='	        unnumbered barline, rendered with partial barline (mid)
     =29`	beginning of measure 29, rendered with partial barline (top)
     =29-	beginning of measure 29, no barline drawn
     ==:|!	double barline with repeat, normal/heavy lines
     ==|	logical double barline, visually rendered as single normal line
     |	        not a barline
     29|	not a barline

*** TABLE OF SIGNIFIERS

        0       breve duration
	1       whole duration
	2       half duration
	3       half-note triplet duration
	4       quarter duration
	6       quarter-note triplet duration
	8       eighth duration
	12      eighth-note triplet duration
	16      sixteenth duration
	24      sixteenth-note triplet duration
	32      thirty-second duration
	64      sixty-fourth duration
	128     one-hundred and twenty-eighth duration
	.       duration augmentation dot (must follow a number)
	-       flat sign (minus character)
	--      double-flat (two successive minus characters)
	a-g     absolute pitches above middle C
	A-G     absolute pitches below middle C
	#       sharp
	##      double sharp
	h       end glissando
	j       harmonic
	k       partial beam extending leftward
	kk      two partial beams extending leftward
	m       mordent (semitone)
	n       natural sign
	p       designator of a note subsequent to an appoggiatura
	q       acciaccatura (grace note signifier; in lieu of duration)
	r       rest
	t       trill (semitone)
	u       down-bow
	v       up-bow
	w       inverted mordent (semitone)
	x       editorial interpretation; immediately preceding signifier is
                  interpreted
	xx      editorial interpretation; entire data token is interpreted
	y       editorial mark:  invisible symbol; unprinted note-, rest-, or
	          barline-attribute, but logically implied
	yy      editorial mark:  invisible symbol; unprinted note, rest, or
	          barline, but logically implied
	z       sforzando
	H       begin glissando
	I       generic articulation (unspecified articulation)
	J       end beam
	JJ      end two beams
	K       partial beam extending rightward
	KK      two partial beams extending rightward
	L       start beam
	LL      start two beams
	M       mordent (whole tone)
	O       generic ornament (unspecified ornament)
	P       appoggiatura note designator
	Q       groupetto note designator
	R       signified ornament ends with a turn
	S       turn
	$       Wagnerian turn
	T       trill (whole tone)
	W       inverted mordent (whole tone)
	X       editorial intervention; immediately preceding signifier is an
	          editorial addition
	XX      editorial intervention; entire data token is an editorial
                  addition
	Y       editorial mark:  sic marking; information is encoded
	          literally, but is questionable
	YY      editorial mark:  sic marking; entire data token is encoded
	          literally, but is questionable
	<space> (space character) multiple-stop conjunction -- indicates
	        joint note-tokens
	=       barline; == double barline
	[       first note of a tie
	]       last note of a tie
	_       middle note(s) of a tie (underscore)
	(       slur start
	)       slur end
	{       phrase mark (start)
	}       phrase mark (end)
	;       pause sign
	'       staccato mark
	s       spiccato
	"       pizzicato mark
	`       attacca mark
	~       tenuto mark
	^       accent mark
	:       arpeggiation (of multi-note chord)
	,       breath mark
	/       up-stem
	\       down-stem
	&       elision marker (for slurs or phrases)
	?       editorial mark: immediately preceding signifier has accompanying
	          editorial footnote
	??      editorial mark: entire preceding data token has accompanying
	          editorial footnote

*** SUMMARY

| signified                           | signifier(s)        | comments                     |
|-------------------------------------+---------------------+------------------------------|
| 1. open phrase elision indicator    | &                   | must precede {               |
| 2. open phrase mark                 | {                   |                              |
| 3. open slur elision indicator      | &                   | must precede (               |
| 4. open slur                        | (                   |                              |
| 5. open tie                         | [                   |                              |
| 6. duration                         | 0123456789          | any combination; signifiers  |
| may be repeated                     |                     |                              |
| 7. augmentation dot(s)              | .                   | signifier may be repeated    |
| 8. pitch                            | abcdefgABCDEFG      | only one of; signifier may   |
| be repeated                         |                     |                              |
| 9. accidental                       | - or # or n         | - and # may be repeated      |
| 10. pause                           | ;                   |                              |
| 11. ornament                        | MmS$TtWwR or O      | O precludes others; no repe- |
| tition of a given signifier;        |                     |                              |
| must appear in order given          |                     |                              |
| 12. appoggiatura designator         | p or P              |                              |
| 13. acciaccatura designator         | q                   |                              |
| 14. groupetto designator            | Q                   |                              |
| 15. articulation                    | z ' " ` ~ ^ : or I  | I precludes others; no re-   |
| petition of a given signifier;      |                     |                              |
| must appear in order given          |                     |                              |
| 16. bowing                          | u or v              | only one of                  |
| 17. stem-direction                  | / or \              | only one of                  |
| 18. beaming                         | L or J              | signifiers may be repeated   |
| 19. partial beaming                 | k or K              | signifiers may be repeated   |
| 20. user-defined marks              | il                  | one or more of;              |
| NUVZ                                | may be repeated but |                              |
| @ % +                               | < >                 | must be in order given       |
| 21. closed or continuing tie        | ] or _              |                              |
| 22. closed slur elision indicator   | &                   | must precede )               |
| 23. closed slur                     | )                   |                              |
| 24. closed phrase elision indicator | &                   | must precede }               |
| 25. closed phrase mark              | }                   |                              |
| 26. breath mark                     | ,                   |                              |
| 27. editorial marks                 | xx or XX            |                              |
| 28. editorial marks                 | yy or YY            |                              |
| 29. editorial marks                 | ??                  |                              |
|                                     |                     |                              |

** Essen Folksongs Data

#+begin_src python :results silent
ESSEN_ROOT = pathlib.Path("data/essen")

ESSEN_REGIONS = ["europa", "asia", "africa", "america"]
#+end_src

** Parsing decisions and functions
<<sec:parsing>>
According to the =**kern= specification, each token consists of a combination of signifiers
encoding duration, pitch, accidentals, rests, ornaments, articulation, beaming, editorial
marks, and other information.

For the purpose of melodic expectation modeling, we define *musical events* as
notes and rests with the following properties:

- *Kept information*:
  - Duration digits and dots (=0–9= and =.=).
  - Pitch letters (=a–g= / =A–G=) and accidentals (_ =, =-=, =#=, =n=).
  - Rest marker =r= (and potentially pause =;=) to represent silence.

- *Removed information*:
  - Ornaments (trills, mordents, turns, etc.).
  - Appoggiaturas, acciaccaturas (grace notes), and groupettos.
  - Articulation, bowing, stem direction, beaming, partial beaming.
  - User-defined and editorial marks.

This follows the manual’s distinction between core syntactic information and
decorative or editorial notation and matches common practice in IDyOM-style
melodic modeling where durationless ornaments and purely notational details
are excluded from the event stream.

#TODO:
GROUPING_CHARS: 

*** Elements definitions
#+begin_src python :results silent
# Core signifier sets
DURATION_CHARS = set("0123456789.")
PITCH_CHARS = set("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ")
ACCIDENTAL_CHARS = set("_-#n")
REST_CHAR = "r"
PAUSE_CHAR = ";"
GROUPING_CHARS = set("{}()[]")

# Non-core signifiers (to be removed)
ORNAMENT_CHARS = set("Mm$STtwWRO")     # ornaments
APPOGGIATURA_CHARS = set("pP")          # appoggiaturas
GRACE_CHAR = "q"                        # acciaccaturas
GROUPETTO_CHAR = "Q"                    # groupettos
ARTICULATION_CHARS = set("z'\"`^~:I")   # articulations
BOWING_CHARS = set("uv")                # bowing positions
STEM_DIR_CHARS = set("/\\")             # stem direction
BEAM_CHARS = set("LJ")                  # beaming
PARTIAL_BEAM_CHARS = set("kK")          # partial beaming
EDITORIAL_CHARS = set("xXyY?")          # editorial marks
USER_MARK_CHARS = set("iltNUVZ@%+")     # user-defined marks

NON_CORE_CHARS = (
    ORNAMENT_CHARS
    | APPOGGIATURA_CHARS
    | ARTICULATION_CHARS
    | BOWING_CHARS
    | STEM_DIR_CHARS
    | BEAM_CHARS
    | PARTIAL_BEAM_CHARS
    | EDITORIAL_CHARS
    | USER_MARK_CHARS
)
#+end_src

*** Helper functions
<<sec:helper>>
Above we defined which elements and characters are core for the analysis and processing
of data in order to prepare it for modelling. In this section we will define helper functions
to recognise said characters and clean the =**kern= files to prepare them for EDA and modelling.

Instead of directly defining a helper function for each unnecessary element in the data, we
just focus for now on null tokens and durationless ornaments that were defined previously to
avoid overcrowding later on the full cleaning function. Elements such as interpretations,
tandems and comments are easily included in the bigger function, having small helper functions
would be a good addition but it is not necessary for such small elements.

Since these do not represent musical events, we do not need to include them in the process.
Better skip them now to avoid unnecessary elements in the data.

Even though for a more detailed and elaborate study of the musical data elements such as
acciaturas and groupettos might be useful and interesting, we will opt to remove them for now.
In case we want to work with their inclusion later on, we can simply rerun the cleaning of
the data without the removal of these characters.

#+begin_src python :results silent
def is_null_token(line):
  return line.startswith(".")

def has_grace_or_groupetto(tok: str) -> bool:
  # Durationless ornaments that should not be counted as events.
  return (GRACE_CHAR in tok) or (GROUPETTO_CHAR in tok)
#+end_src

We will stript all ornaments, bowing, stems, beamings and editorial marks as well to leave only
the minimal syntactic information needed to define duration and pitch (including rests).
This way we focus on structural melodic content rather than detailed notations. 

#+begin_src python :results silent
def strip_non_core_signifiers(tok: str) -> str:
    """
    Remove ornaments, articulation, beams, editorial marks and other
    non-core signifiers, preserving duration, pitch, accidentals and rest.
    """
    return "".join(ch for ch in tok if ch not in NON_CORE_CHARS)
#+end_src

*** Parsing tokens

The =parse_kern_token= function is the main function for the parsing process.
It gathers the previous helper functions defined above in order to create a single
=**kern= token into KernEvents.
Why do we create a class for this?
- We want to turn messy tokens into a structured, clean and homogenous event that will make it easier
  to analyse and feed the models later on.

In this section, we focus on the cleaning of the data. Ornaments and editorial notations are not
necesary for our purpose and will just end up creating noise for the ultimate modelling section. 

#+begin_src python :results output
@dataclass
class KernEvent:
    duration: str
    pitch: str
    is_rest: bool


def parse_kern_token(tok: str) -> Optional[KernEvent]:
    tok = tok.strip()
    if not tok or is_null_token(tok):
        return None
    if has_grace_or_groupetto(tok):
        return None

    tok = strip_non_core_signifiers(tok)

    # strip grouping / phrasing markers that can wrap tokens
    while tok and tok[0] in GROUPING_CHARS:
        tok = tok[1:]
    while tok and tok[-1] in GROUPING_CHARS:
        tok = tok[:-1]
    if not tok or is_null_token(tok):
        return None

    # Extract duration (leading digits + dots)
    i = 0
    dur_chars = []
    while i < len(tok) and tok[i].isdigit():
        dur_chars.append(tok[i])
        i += 1
    while i < len(tok) and tok[i] == ".":
        dur_chars.append(tok[i])
        i += 1
    duration = "".join(dur_chars)
    if not duration:
        return None

    pitch_part = tok[i:]
    if not pitch_part:
        return None

    is_rest = (REST_CHAR in pitch_part) or (PAUSE_CHAR in pitch_part)
    if is_rest:
        pitch_norm = "r"
    else:
        pitch_chars = [ch for ch in pitch_part if ch in PITCH_CHARS or ch in ACCIDENTAL_CHARS]
        if not pitch_chars:
            return None
        pitch_norm = "".join(pitch_chars)

    return KernEvent(duration=duration, pitch=pitch_norm, is_rest=is_rest)

#+end_src

#+RESULTS:

**** Example

#+BEGIN_SRC python :results output
# Some example **kern note tokens, including ornaments and rests.
tokens = [
    "4c",          # quarter-note C
    "8g#",         # eighth-note G sharp
    "4cL",         # quarter-note C with beaming (L) that should be stripped
    "16bq",        # grace-note B (q) that should be discarded entirely
    "8.cc#",       # dotted eighth-note C-sharp
    "4r",          # quarter rest
    "4G$'",        # quarter-note G with ornament ($) and articulation (') to drop
    ".",
]

for tok in tokens:
    ev = parse_kern_token(tok)
    print(f"token={tok!r} ->", ev)
#+END_SRC

#+RESULTS:
: token='4c' -> KernEvent(duration='4', pitch='c', is_rest=False)
: token='8g#' -> KernEvent(duration='8', pitch='g#', is_rest=False)
: token='4cL' -> KernEvent(duration='4', pitch='c', is_rest=False)
: token='16bq' -> None
: token='8.cc#' -> KernEvent(duration='8.', pitch='cc#', is_rest=False)
: token='4r' -> KernEvent(duration='4', pitch='r', is_rest=True)
: token="4G$'" -> KernEvent(duration='4', pitch='G', is_rest=False)
: token='.' -> None

** Loading and cleaning the Essen corpus
This section walks over the Essen folder structure (grouped by country/region),
parses each file using the token‑level rules above.
The result is a list of cleaned event sequences with metadata.

We loop over each region found in the Essen data folder. For each folder we recursively
find all Humdrum =**kern= files.
This function was mainly created to check whether all the files were available and selectable for
for the next steps of the project. Based on our results, the files are readable and can be used
for further processing. 

#+begin_src python :results silent
def iter_essen_files():
    """
    Yield (path,) for every .krn file anywhere under data/essen.
    """
    for path in ESSEN_ROOT.rglob("*.krn"):
        yield path
#+end_src

#+begin_src python :results output
files_seen = list(iter_essen_files())
print("Files seen:", len(files_seen))
#+end_src

#+RESULTS:
: Files seen: 8472

#+begin_src python :results output
for i, p in enumerate(iter_essen_files()):
    print(i, "->", p)
    if i == 9:
        break
#+end_src

#+RESULTS:
#+begin_example
0 -> data/essen/europa/misc/island02.krn
1 -> data/essen/europa/misc/steier01.krn
2 -> data/essen/europa/misc/norge02.krn
3 -> data/essen/europa/misc/island01.krn
4 -> data/essen/europa/misc/ellas01.krn
5 -> data/essen/europa/misc/steier03.krn
6 -> data/essen/europa/misc/steier02.krn
7 -> data/essen/europa/misc/norge01.krn
8 -> data/essen/europa/misc/steier06.krn
9 -> data/essen/europa/misc/emmenth1.krn
#+end_example


After obtaining the =**kern= files, we need to extract from the full file the musical
representations that we need for future training as explained in the [[sec:parsing][parsing section]]
and the [[sec:helper][helper functions]] definition.
This way, we apply the classification rules from the Humdrum spec:
We skip empty lines and the following attributes:
- global and local comments
- interpretation lines that declare spyne types
- tandem interpretations (e.g., name of voices)
- barlines

With this function we apply the cleaning previously defined with =parse_kern_tokens= on
the full Humdrum file. 

For the remaining lines, we split the data on tab and take the first token, assuming monophonic
melodies and one relevant spine per file (which is how Essen is structured for melodic analysis)

#+begin_src python :results output
def load_kern_melody(path: pathlib.Path):
    out = []
    raw_tokens = 0
    parsed_tokens = 0

    with path.open("r", encoding="utf-8", errors="ignore") as f:
        for raw in f:
            line = raw.strip()
            if not line:
                continue

            if line.startswith(("*", "!", "=", ".")):
                continue

            tok = line.split("\t")[0].strip()
            raw_tokens += 1

            ev = parse_kern_token(tok)
            if ev is not None:
                out.append(ev)
                parsed_tokens += 1

    return out

test_path = pathlib.Path("data/essen/america/mexico/mexico02.krn")
events = load_kern_melody(test_path)
print("EVENTS:", len(events))
for i, ev in enumerate(events[:10]):
    print(i, ev)
#+end_src

#+RESULTS:
#+begin_example
EVENTS: 88
0 KernEvent(duration='8', pitch='r', is_rest=True)
1 KernEvent(duration='8', pitch='c', is_rest=False)
2 KernEvent(duration='8', pitch='c', is_rest=False)
3 KernEvent(duration='8', pitch='c', is_rest=False)
4 KernEvent(duration='8', pitch='f', is_rest=False)
5 KernEvent(duration='4', pitch='r', is_rest=True)
6 KernEvent(duration='8', pitch='a', is_rest=False)
7 KernEvent(duration='8', pitch='r', is_rest=True)
8 KernEvent(duration='8', pitch='c', is_rest=False)
9 KernEvent(duration='8', pitch='c', is_rest=False)
#+end_example

Now, as the last step, we build the full clean corpus.
This function iterates over each file (as shown before all files are captured).
For each file, we obtain its events with the previously defined =load_kern_melody= function.
After obtaining the files, we derive a simple contry label from the path by taking the second
element of the relative path. This way we can group the results based on the countries and regions.

The function returns two lists, the =melodies= with the events (KernEvent) from each melody.
And second, the =meta_list= contains the metadata from each file, that is its name, path, region,
country and length of the melody. 

#+begin_src python :results silent
MIN_EVENTS = 20

def collect_clean_essen():
    melodies = []
    meta_list = []

    for path in ESSEN_ROOT.rglob("*.krn"):
        events = load_kern_melody(path)
        # if len(events) < MIN_EVENTS:
        #     continue

        # derive continent/country from relative path
        rel_parts = path.relative_to(ESSEN_ROOT).parts
        continent = rel_parts[0] if len(rel_parts) > 0 else "unknown"
        country = rel_parts[1] if len(rel_parts) > 1 else "unknown"

        melodies.append(events)
        meta_list.append({
            "filename": path.name,
            "path": str(path),
            "continent": continent,
            "country": country,
            "length": len(events),
        })
    return melodies, meta_list
#+end_src

#+begin_src python :results output
melodies, meta = collect_clean_essen()
print("Number of melodies:", len(melodies))
#+end_src

#+RESULTS:
: Number of melodies: 8472

#+begin_src python :results output
print(len(melodies[0]))
#+end_src

#+RESULTS:
: 48

Let's inspect some of the melodies
#+begin_src python :results output
idxs = random.sample(range(len(meta)), 20)
for i in idxs:
    print(i, meta[i]["continent"], meta[i]["country"], meta[i]["filename"], "len:", meta[i]["length"])
#+end_src

#+RESULTS:
#+begin_example
3277 europa deutschl deut1643.krn len: 57
8465 asia china natmn035.krn len: 91
2786 europa deutschl deut4904.krn len: 74
2391 europa deutschl deut4665.krn len: 52
1701 europa deutschl deut2753.krn len: 66
6599 asia china shanx131.krn len: 52
2651 europa deutschl deut4964.krn len: 74
238 europa deutschl deut4141.krn len: 30
4804 europa deutschl deut520.krn len: 71
6322 asia china shanx217.krn len: 52
1328 europa deutschl deut2705.krn len: 68
2123 europa deutschl deut3792.krn len: 37
1019 europa deutschl deut3049.krn len: 55
6275 asia china shanx548.krn len: 20
5891 europa elsass elsass19.krn len: 23
3029 europa deutschl deut1241.krn len: 27
3157 europa deutschl deut1046.krn len: 45
2976 europa deutschl deut0767.krn len: 24
3156 europa deutschl deut2229.krn len: 45
5940 europa elsass elsass66.krn len: 55
#+end_example

#+begin_src python :results output
m0 = melodies[0]
print("First melody: length", len(m0))
print("First 10 events:")
for i, ev in enumerate(m0[:10]):
    print(i, ev)
#+end_src

#+RESULTS:
#+begin_example
First melody: length 48
First 10 events:
0 KernEvent(duration='8.', pitch='a', is_rest=False)
1 KernEvent(duration='16', pitch='b', is_rest=False)
2 KernEvent(duration='8', pitch='ccn', is_rest=False)
3 KernEvent(duration='8.', pitch='b', is_rest=False)
4 KernEvent(duration='16', pitch='a', is_rest=False)
5 KernEvent(duration='8', pitch='g#', is_rest=False)
6 KernEvent(duration='8.', pitch='a', is_rest=False)
7 KernEvent(duration='16', pitch='b', is_rest=False)
8 KernEvent(duration='8', pitch='ccn', is_rest=False)
9 KernEvent(duration='4', pitch='b', is_rest=False)
#+end_example

#+begin_src python :results output
events_df = []
for i, (events, m) in enumerate(zip(melodies, meta)):
    for j, ev in enumerate(events):
        row = m.copy()
        row.update({
            'melody_id': i,
            'position': j,
            'pitch': ev.pitch,
            'duration': ev.duration,
            'is_rest': ev.is_rest
        })
        events_df.append(row)

df_vp = pd.DataFrame(events_df)
print(df_vp.shape)
print(df_vp.sample(5))
#+end_src

#+RESULTS:
: (464343, 10)
:             filename                                            path continent   country  length  melody_id  position pitch duration  is_rest
: 375097   han0959.krn           data/essen/asia/china/han/han0959.krn      asia     china      40       7281        29   ccc       16    False
: 433786   han0767.krn           data/essen/asia/china/han/han0767.krn      asia     china     100       8037        99     d        2    False
: 93779   kindr202.krn  data/essen/europa/deutschl/kinder/kindr202.krn    europa  deutschl      36       1826         1    dd        8    False
: 378046   han0185.krn           data/essen/asia/china/han/han0185.krn      asia     china      73       7326        38     b       16    False
: 1296    siebethl.krn             data/essen/europa/misc/siebethl.krn    europa      misc     150         21       140     b       8.    False

#+begin_src python :results output
print(df_vp.head(15))
#+end_src

#+RESULTS:
#+begin_example
        filename                                 path continent country  length  melody_id  position pitch duration  is_rest
0   island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0         0     a       8.    False
1   island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0         1     b       16    False
2   island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0         2   ccn        8    False
3   island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0         3     b       8.    False
4   island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0         4     a       16    False
5   island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0         5    g#        8    False
6   island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0         6     a       8.    False
7   island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0         7     b       16    False
8   island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0         8   ccn        8    False
9   island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0         9     b        4    False
10  island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0        10     r        8     True
11  island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0        11     b        4    False
12  island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0        12     b        8    False
13  island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0        13   ccn        4    False
14  island02.krn  data/essen/europa/misc/island02.krn    europa    misc      48          0        14    dd        8    False
#+end_example

* Data Validation with Humdrum Tools
** Selecting data
The Humdrum data type counts as well with its tool kit that allows for the inspection and
cleaning of raw =**kern= files. It is interesting to use it to double check wheter the manual
preprocessing done is correct. Based on the results, the data obtained from the files corresponds
to what is obtained from the Kumdrum files.

This code block does the following:
- rid removes interpretive data, that is, it strips non-musical lines from Humdrum files.
- G removes global comments
- L removes local comments
- I removes interpretations

Next, =awk -F'\t' '{print $1}'= takes care of selecting only the first spine of the kern file,
that is, in case we have any polyphonies on our corpus, it will be turned into a monophony by
solely selecting the first voice (spine). The field separator (F) is set to tabs, since that is
the standard separations on kern files.

Finally, we get rid of the barlines, as explained before, they offer no musical information, they
are just structural separators that do not bring meaninful information for future modelling. 

#+begin_src bash :results output
rid -GLI data/essen/europa/misc/island02.krn \
  | awk -F'\t' '{print $1}' \
  | grep -v '^=' \
  > /tmp/island02.tokens

head -n 20 /tmp/island02.tokens
#+end_src

#+RESULTS:
#+begin_example
{8.a
16b
8ccn
8.b
16a
8g#
8.a
16b
8ccn
4b
8r}
{4b
8b
4ccn
8dd
4.ee
4dd
8r}
{4ccn
8ccn
#+end_example

** Validation

#+begin_src bash :results output
find data/essen -type f \( -name "*.krn" -o -name "*.kern" \) | sort > essen_files.txt
wc -l essen_files.txt
#+end_src

#+RESULTS:
:     8472 essen_files.txt

#+begin_src bash :results output
mkdir -p audit/logs

while read -r f; do
  base=$(basename "$f")
  mint "$f" >audit/logs/"$base".out 2>audit/logs/"$base".err
  echo "$?,${f}" >> audit/validator_exitcodes.csv
done < essen_files.txt
#+end_src

#+RESULTS:

#+begin_src bash :results output
rid -GLI data/essen/europa/misc/island01.krn | extract -i '**kern' > out 2> err
status=$?

echo "$status,$f" >> audit/extract_exitcodes.csv
#+end_src

#+RESULTS:

** Viewpoint availability

Similar to what we did in the cleaning of the files with Python, in this case we do it with the Humdrum
tools to double check the cleaning worked well (even though it was shown above that it was). This time
we also take into account detecting notation that might not be found in files but that it is crucially
important for the future creation of "viewpoints". In this step we want to make sure that we only
keep the files that contain all the necessary information, that is for example duration, pitch, keys,

*** Pitch
We want to check that all the files include pitch values, otherwise the file would be empty and
would be useless for our model.

In this case, we a file is flagged if all non-bar tokens are rests (r) or empty.

#+begin_src bash :results output
rm -f audit/no_pitched_notes.csv
: > audit/no_pitched_notes.csv

while IFS= read -r f; do
  f="${f%$'\r'}"   # guard against CRLF

  if ! LC_ALL=C extract -i '**kern' "$f" \
    | sed 's/^,//' \
    | grep -Ev '^(!!!|!!|!|\*|=|\.|$)' \
    | grep -Eq '[abcdefgABCDEFG]'; then
    echo "$f" >> audit/no_pitched_notes.csv
  fi
done < essen_files.txt

wc -l audit/no_pitched_notes.csv
#+end_src

#+RESULTS:
:        1 audit/no_pitched_notes.csv

In this process, we take into account several details from each file, including some of the files
contained commas after each note, and cleaning for elements that do not express musical information.
We conduct a similar cleaning process as what was done with =load_kern_melody=. However, in this case we
want to make sure that all the files contain actual pitch representations to avoid using invalid melodies.

The final result gives us one single file. Let's inspect it and see what seems to be the issue and whether
it is worthy to keep it or remove it from the corpus. 

#+begin_src bash :results output
extract -i '**kern' data/essen/asia/china/han/han0953.krn | head -n 30
#+end_src

#+RESULTS:

Nothing seems to be returned, we can take a look into it with =load_kern_melody= and inspect whether the
events are null or actuall appear. 

#+begin_src python :results output
events = load_kern_melody(pathlib.Path("data/essen/asia/china/han/han0953.krn"))
print("EVENTS:", len(events))
#+end_src

#+RESULTS:
: EVENTS: 0

We see that this file is empty, just contains commentsm interpretations and editoral marks,
elements that do not symbolize musical events, and therefore not important for our research.

#+begin_src python :results output
os.remove(pathlib.Path("data/essen/asia/china/han/han0953.krn"))
#+end_src

*** Duration
#+begin_src bash :results output
rm -f audit/missing_duration.csv
: > audit/missing_duration.csv

while IFS= read -r f; do
  f="${f%$'\r'}"

  if LC_ALL=C extract -i '**kern' "$f" \
    | sed 's/^,//' \
    | grep -Ev '^(!!!|!!|!|\*|=|\.|$)' \
    | sed -E 's/^[\[{(]+//' \
    | sed -E 's/[}\]]+$//' \
    | grep -Ev '^[0-9]' \
    | grep -q .; then
    echo "$f" >> audit/missing_duration.csv
  fi
done < essen_files.txt

wc -l audit/missing_duration.csv
#+end_src

#+RESULTS:
:        0 audit/missing_duration.csv

After taking into account all the elements and structures that are do not needed (as
previously explained in the Pitch cleaning section), we can see that all the files contain
duration information, all of them are valid and we can keep them for future modeling and
analysis.

*** Structural integrity
#+begin_src bash :results output
> audit/extract_fail.csv

while read -r f; do
  if ! rid -GLI "$f" | extract -i '**kern' > /dev/null 2>&1; then
    echo "$f" >> audit/extract_fail.csv
  fi
done < essen_files.txt

wc -l audit/extract_fail.csv
#+end_src

#+RESULTS:
:        0 audit/extract_fail.csv

** Statistical Analysis

Humdrum tools only provide statistial tools to inspect each kern file individually. If we want
to inspect all the songs at the same time, one option is to concatenate all the songs together,
but this could in turn provide misleading information regarding the overall statistical data
obtained.
Nevertheless, it is interesting to look into how these tools perform and what their output tell us
about our data.

*** Intervals
The function =mint= looks into the melodic intervals of each song
#+begin_src bash :results output
mint data/essen/america/mexico/mexico02.krn | grep -v '^[!*]' | head -n 10
#+end_src

#+RESULTS:
#+begin_example
{r
[c]
P1
P1
=1
+P4
r
+M3
r
-M6
#+end_example

We can obtain a bit more of information on it with the count of the occurrance of each interval.

#+begin_src bash :results output
mint data/essen/america/mexico/mexico02.krn | grep -v '^[!=*]' | sort | uniq -c 
#+end_src

#+RESULTS:
#+begin_example
   5 +M2
   6 +M3
   5 +P4
   7 +m3
  10 -M2
   1 -M2}
   3 -M3
   1 -M6
   1 -P4
   2 -P5
   4 -m2
   3 -m3
  22 P1
   1 [c]
   6 r
   3 r}
   8 {r
#+end_example

From this analysis we can see that the most common (with the higher number of occurrences) intervals are
P1 (perfect unison) and -M2 (descending Major Second). According to the paper "Predicting Variation of Folk
Songs" (Janssen et al., 2017), the most common and influential melodic intervals are small pitch intervals,
a standard feature of the Dutch folk song corpus.
The presence and frequency of these small intervals carry specific psychological and structural meanings in the
context of folk song variation:

• **Predictor of Stability**: Phrases containing small pitch intervals are more stable and resist change more effectively
as they are transmitted through oral tradition. In other words, phrases with smaller intervals are less subject to
variation over time than those with large leaps

• **Facilitation of Recall**: Small intervals enhance the memorability of a melody. Because these intervals are
easier for singers to remember and reproduce, they contribute to the long-term retention of the piece in a musical tradition.

• **Melodic Expectancy (Pitch Proximity)**: Small intervals correspond to the principle of pitch proximity, which
states that listeners inherently expect the next note in a melody to be close in pitch to the one they just heard. The
paper uses "high average proximity" as a formalization of expectancy—meaning phrases with small intervals contain
"highly expected melodic material".

In summary, the prevalence of small intervals in folk songs means these pieces are structured for efficient communication
and recall, aligning with human cognitive predispositions that favor predictable, proximate pitch patterns.

We can obtain the occurance of these type of intervals on the whole corpus with a bit more work and check whether these
statements are also present in the corpus in general. In the following code block we read all the files, instead of
concatenating them all together, =mint= is called individually for each melody inside the while loop:

#+begin_src bash :results output
while IFS= read -r f; do
  f="${f%$'\r'}"
  continent=$(echo "$f" | awk -F'/' '{print $3}')
  mint "$f" 2>/dev/null \
    | rid -GLId \
    | sed 's/[{}()]//g' \
    | grep -Ev '^(r|$)' \
    | sed "s/^/${continent},/"
done < essen_files.txt > audit/mint_by_continent.csv
#+end_src

#+RESULTS:

#+begin_src python :results output
df_int = pd.read_csv(
    "audit/mint_by_continent.csv",
    header=None,
    names=["continent", "interval"]
)

mask = df_int['interval'].astype('str').str.contains('=')
df_int = df_int[~mask]
print(df_int)
#+end_src

#+RESULTS:
#+begin_example
       continent interval
0         africa     [dd]
2         africa      +P4
3         africa      +M2
4         africa      +m2
5         africa      +M2
...          ...      ...
574202    europa      -m3
574203    europa       P1
574204    europa      -M2
574205    europa      -m2
574207    europa      +m2

[447000 rows x 2 columns]
#+end_example

Throughout the corpus it still seems that small pitch intervals are the most occurrent in this corpus.
This translates to a similar behaviour of folk music patterns across countries and regions.
We can count the occurances of each interval per continent and check how this shows in a graph for more visual aid:

#+begin_src python :results output
print(df_int.groupby(["continent"])["interval"].value_counts().groupby("continent").head(5).to_frame())
#+end_src

#+RESULTS:
#+begin_example
                    count
continent interval       
africa    -m2          27
          +m2          23
          P1           23
          +M2          21
          -M2          20
america   P1          180
          -M2         115
          +M2          65
          +M3          54
          +m3          46
asia      -M2       32025
          +M2       24064
          P1        22413
          -m3       17443
          +m3       14695
europa    P1        64186
          -M2       61806
          +M2       39461
          -m2       24952
          +m2       18572
#+end_example

This shows the top 5 more repeated intervals per continent. As expected, the most common are very small intervals,
such as minor and major seconds, as well as perfect unison. We cannot confirm this is the general rule for africa
since we only count with one melody belonging to this continent, however it still fits the assumptions and the
conclusions drawn from the paper "Predicting Variation of Folk Songs" (Janssen et al., 2017).

#+begin_src python :results file graphics :file interval_by_continent.png
df_top = (
    df_int
    .groupby("continent")["interval"]
    .value_counts()
    .groupby("continent")
    .head(10)
    .rename("count")
    .reset_index()
)

# Normalize per continent
df_top["proportion"] = df_top.groupby("continent")["count"].transform(
    lambda x: x / x.sum()
)

plt.figure(figsize=(14, 5))
g = sns.barplot(
    data=df_top,
    x="interval",
    y="proportion",
    hue="continent",
    order=df_int["interval"].value_counts().head(10).index,
    palette="viridis"
)

sns.move_legend(g, "upper right", title="Continents")

plt.xticks(rotation=45)
plt.title("Top intervals by continent (normalized)")
plt.tight_layout()
plt.savefig("interval_by_continent.png", dpi=80, bbox_inches="tight")
plt.close()
#+end_src

#+RESULTS:
[[file:interval_by_continent.png]]

From the graph we can observe that even though each continent presents small intervals as most employed in their
melodies, there are still some differences among the use of intervals and their usage.
For example, each continent uses in a similar proportion the descending M2 interval (major second).
While America, together with Europa, presents the higher proportion of P1 (perfect unison), Asia and Africa show
a smaller yet similar proportion in the usage of this interval. Interestingly, Africa shows the highest proportion
of minor intervals, ascending and descending. We cannot take this as the ground truth for this continent since we
only count with one song belonging to this region.
Overall, we see a very similar representation of intervals across the four continents represented in this corpus.

*** Entropy (Information Content)

infot — calculate information theory measures for Humdrum inputs.
provides a general-purpose tool for measuring the probability relationships
between user-selected data tokens.

- b output information (in bits) for each unique data token

#+begin_src bash :results output
infot -b data/essen/america/mexico/mexico01.krn
#+end_src

#+RESULTS:
#+begin_example
2f	6.392
==	6.392
8f}	6.392
4b-	5.392
4a	6.392
4e	5.392
4f	5.392
8dd	4.807
2g}	4.807
{8cc	4.807
4r}	6.392
2a}	5.392
4.c}	6.392
8a	3.807
8cc	4.392
8c	2.807
8d	5.392
8e	4.392
8f	4.807
=10	6.392
{8c	4.392
8g	4.070
=11	6.392
4cc	6.392
=1	6.392
=12	6.392
=13	6.392
=2	6.392
{8f	6.392
=14	6.392
=3	6.392
=15	6.392
=4	6.392
=16	6.392
=5	6.392
=6	6.392
=7	6.392
=8	6.392
=9	6.392
8b-	4.807
#+end_example

#+begin_src bash :results output
while IFS= read -r f; do
  f="${f%$'\r'}"
  result=$(mint "$f" 2>/dev/null \
    | rid -GLId \
    | sed 's/[{}()]//g' \
    | grep -Ev '^(r|$)' \
    | infot -b 2>/dev/null \
    | awk '{sum += $NF; n++} END {if (n > 0) printf "%.4f", sum/n}')

  if [ -n "$result" ]; then
    echo "$f,$result"
  fi
done < essen_files.txt > audit/infot_intervals.csv
#+end_src

#+RESULTS:

#+begin_src bash :results output
head -10 audit/infot_intervals.csv
#+end_src

#+RESULTS:
#+begin_example
data/essen/africa/arabic01.krn,5.1651
data/essen/america/mexico/mexico01.krn,5.6065
data/essen/america/mexico/mexico02.krn,5.6549
data/essen/america/mexico/mexico03.krn,5.6065
data/essen/america/mexico/mexico04.krn,5.6549
data/essen/america/misc/brasil01.krn,4.0897
data/essen/america/misc/canada01.krn,4.9314
data/essen/america/usa/usa01.krn,5.4886
data/essen/america/usa/usa02.krn,4.9615
data/essen/america/usa/usa03.krn,5.4544
#+end_example

* EDA
** Melody inspection

Even though on our cleaning and preprocessing steps we immediately applied the selection of only
one voice, it is interesting to check whether any of our songs are actually polyphonic.

Based on the results with python and Humdrum tools, all of our melodies are monophonic, which
makes the processing much easier. 

#+begin_src bash :results output
find data/essen -name "*.krn" | while read f; do
  grep -m 1 '^\*\*' "$f" | awk -F'\t' '{print NF}'
done | sort | uniq -c
#+end_src

#+RESULTS:
: 8473 1

#+begin_src python :results output
voice_counts = {}

for f in Path("data/essen").rglob("*.krn"):
    with f.open(encoding="utf-8", errors="ignore") as fh:
        for line in fh:
            if line.startswith("**"):
                n_voices = line.count("\t") + 1
                voice_counts[n_voices] = voice_counts.get(n_voices, 0) + 1
                break

for k in sorted(voice_counts):
    print(f"{k} voices: {voice_counts[k]} files")
#+end_src

#+RESULTS:
: 1 voices: 8473 files

Both the Humdrum tools and our manual Python inspection show that we just have monophonic music, which makes
the whole process much easier.
However, this just applies to the Essen corpus, luckly we already accounted for polyphonic music in the preprocessing in case
the other corpus employed (The Meertens Tune Collecion) does indeed contain multiple voices. 

** Obtaining keys

An interesing addition to the data that will be employed later on (as well as for the EDA) is the key
and mode of the melodies.
Humdrum provides tools necessary to estimate both for each melody. 

#+begin_src bash :results output
key data/essen/europa/misc/island02.krn
#+end_src

#+RESULTS:
: Estimated key: A minor	(r=0.6230)	confidence:	42.6%

#+begin_src bash :results output
keycor data/essen/europa/misc/island02.krn
#+end_src

#+RESULTS:
: The best key is: A Minor

This "key" command returns the estimated key of each musical piece using Krumhansl’s tonal hiearchy method.
A constraint is that this command is solely designed to detect major and minor modes (tonal system) (cite). It is unlikely
that the data found in the corpus differs from this system, but it is still important to mention it as a limitation
for more complex musical structures that may be used in the future.
Also, key is unable to distinguish enharmonic spellings involving double- or triple- sharps or flats.
That is, G double-sharp major is identified as A major (cite).

The output shows as well the confidence value associated to the estimated key: this is a relative certainty
measure among all keys it considered, not a probability that the piece “is” A minor in an absolute sense

The third value returned is a correlation coefficient (r) measures how strongly the piece’s pitch-class profile matches an ideal
representation of the estimated key. 

#+begin_src bash :results output
mkeyscape -ln data/essen/europa/misc/island01.krn | magick - ./island01_key.png
#+end_src

#+RESULTS:

*** Keys from the kern notation

We can as well obtain they key from the kern files notation. The kern notation usually includes
information as tandem interpretations in the very beginning of the file that can be translated
into the key of the melody (without the tonal system).

This information is given by the tonic and the key signature of the melody.
The tonic represents the first note of the scale in which the melody is set (key).
The key signature defines the key of the melody, that is which notes are altered in said
scale. this includes the notes name and whether they contain sharps or flats. The flats are
represented with =#= and the flats with =-=.

The following section focuses on obtaining these elements from each melody.
However, the tonic and key signature do not provide the major and minor keys.
This will be covered in the next section. 

#+begin_src python :results output
key_tandem_re = re.compile(r'^\*[A-Ga-g](?:#|-)?\s*:\s*$', re.M)
ksig_re = re.compile(r'^\*k\[[^\]]*\]\s*$', re.M)

def key_matches(path: Path=ESSEN_ROOT):
    files = sorted(path.rglob("*.krn"))
    data = []
    for f in files:
        txt = f.read_text(encoding="utf-8", errors="ignore")
        key_m = key_tandem_re.search(txt)
        ksig_m = ksig_re.search(txt)
    
        key_line = key_m.group(0) if key_m else None
        ksig_line = ksig_m.group(0) if ksig_m else None

        data.append({
            'path': str(f),
            'tonic': key_line,
            'key_signature': ksig_line
        })
    return pd.DataFrame(data)


key_df = key_matches(ESSEN_ROOT)
#+end_src

#+RESULTS:

#+begin_src python :results output
print(key_df.sample(10))
#+end_src

#+RESULTS:
#+begin_example
                                                 path tonic key_signature
8364           data/essen/europa/schweiz/suisse23.krn   *G:        *k[f#]
2840  data/essen/europa/deutschl/altdeu2/deut4191.krn   *D:      *k[f#c#]
734             data/essen/asia/china/han/han0659.krn   *G:        *k[f#]
4684      data/essen/europa/deutschl/erk/deut0707.krn   *F:        *k[b-]
741             data/essen/asia/china/han/han0666.krn  *B-:      *k[b-e-]
2611  data/essen/europa/deutschl/altdeu1/deut3962.krn   *F:        *k[b-]
4013   data/essen/europa/deutschl/boehme/deut2551.krn   *G:        *k[f#]
3776   data/essen/europa/deutschl/boehme/deut2314.krn   *G:        *k[f#]
1876        data/essen/asia/china/shanxi/shanx434.krn   *D:      *k[f#c#]
1065            data/essen/asia/china/han/han0990.krn  *B-:      *k[b-e-]
#+end_example

#+begin_src bash :results output
key data/essen/asia/china/han/han0659.krn
#+end_src

#+RESULTS:
: Estimated key: G major	(r=0.8750)	confidence:	33.6%

#+begin_src python :results output
df = pd.merge(df, key_df, on="path")
print(df.sample(5))
#+end_src

#+RESULTS:
:             filename                                            path continent   country  length  melody_id  position pitch duration  is_rest tonic key_signature
: 170883  deut2203.krn     data/essen/europa/deutschl/erk/deut2203.krn    europa  deutschl      75       3340        68     b       16    False   *G:        *k[f#]
: 142173  deut4643.krn  data/essen/europa/deutschl/zuccal/deut4643.krn    europa  deutschl     106       2776        22    b-       16    False  *B-:      *k[b-e-]
: 206719  deut0655.krn     data/essen/europa/deutschl/erk/deut0655.krn    europa  deutschl      52       4092        18    dd        8    False   *G:        *k[f#]
: 263302   deut563.krn     data/essen/europa/deutschl/fink/deut563.krn    europa  deutschl     102       5118        86     c        4    False   *C:          *k[]
: 402301   han0496.krn           data/essen/asia/china/han/han0496.krn      asia     china      80       7626         0    dd        8    False   *F:        *k[b-]

*** Estimated keys with Humdrum tools

With kern tools we can easily create a file with the estimated keys.
As shown before, we employ the command =key= to obtain the estimated key of each melody, together with the
correletion coefficient and the confidence value. The following code block reads through each kern file
found in the essen folder and extracts the mentioned key values. Once all the values are obtained,
these are stored into a csv file. 

#+begin_src bash :results output
find ESSEN_ROOT -name "*.krn" | while read f; do
    key "$f" | awk -v file="$f" '
        /Estimated key:/ {
            key=$3" "$4
            r=$5
            conf=$7
            print file "," key "," r "," conf
        }'
done > estimated_keys.csv
#+end_src

#+RESULTS:

After reading through the csv file, we found that there is no clear structure in it. When reading the
csv file, we make sure to take into accont headers and name the columns for easier manipulation. 

#+begin_src python :results output
df_keys = pd.read_csv(
  "estimated_keys.csv",
  header=None,
  names=["path", "key", "r", "confidence"]
)

df_keys["r"] = (
    df_keys["r"]
    .str.replace(r"[()r=]", "", regex=True)
    .astype(float)
)

df_keys["confidence"] = (
    df_keys["confidence"]
    .str.replace("%", "")
    .astype(float)
)

print(df_keys.columns)
print(df_keys.head())
#+end_src

#+RESULTS:
: Index(['path', 'key', 'r', 'confidence'], dtype='object')
:                                   path      key       r  confidence
: 0  data/essen/europa/misc/island02.krn  A minor  0.6230        42.6
: 1  data/essen/europa/misc/steier01.krn  G major  0.8366         9.3
: 2   data/essen/europa/misc/norge02.krn  G minor  0.7823        45.3
: 3  data/essen/europa/misc/island01.krn  C major  0.7082        34.9
: 4   data/essen/europa/misc/ellas01.krn  G major  0.4829         6.1

#+begin_src python :results output
df_keys["mode"] = df_keys["key"].str.contains("minor").map(
    {True: "minor", False: "major"}
)

df_keys["tonic"] = (
    df_keys["key"]
    .str.replace(" major", "", regex=False)
    .str.replace(" minor", "", regex=False)
)

df_keys["continent"] = df_keys["path"].apply(lambda p: p.split("/")[2])

print(df_keys.head())
#+end_src

#+RESULTS:
:                                   path      key       r  confidence   mode tonic continent
: 0  data/essen/europa/misc/island02.krn  A minor  0.6230        42.6  minor     A    europa
: 1  data/essen/europa/misc/steier01.krn  G major  0.8366         9.3  major     G    europa
: 2   data/essen/europa/misc/norge02.krn  G minor  0.7823        45.3  minor     G    europa
: 3  data/essen/europa/misc/island01.krn  C major  0.7082        34.9  major     C    europa
: 4   data/essen/europa/misc/ellas01.krn  G major  0.4829         6.1  major     G    europa

#+begin_src python :results silent
df_keys.to_csv("estimated_keys.csv", index=False)
#+end_src

#+begin_src python :results output
tab = (
    df_keys
    .groupby(["continent", "mode"])
    .size()
    .unstack(fill_value=0)
)

tab_prop = tab.div(tab.sum(axis=1), axis=0)
print(tab_prop)
#+end_src

#+RESULTS:
: mode          major     minor
: continent                    
: africa     0.000000  1.000000
: america    0.923077  0.076923
: asia       0.755011  0.244989
: europa     0.750845  0.249155

*** Visual representation
#+begin_src python :results file graphics :file major_minor_proportion.png
ax = tab_prop.plot(
    kind="bar",
    stacked=True,
    figsize=(7,4),
    colormap="viridis"
)

ax.set_ylabel("Proportion")
ax.set_xlabel("Continent")
ax.set_title("Proportion of major vs minor modes by continent (Essen corpus)")
ax.legend(title="Mode", bbox_to_anchor=(1.02, 1), loc="upper left")
plt.tight_layout()
plt.savefig("major_minor_proportion.png", dpi=150, bbox_inches="tight")
plt.close()
#+end_src

#+RESULTS:
[[file:major_minor_proportion.png]]

#+begin_src python :results file graphics :file tonic.png
df_keys["tonic"].value_counts().head(10).plot(kind="bar")
plt.title("Most common tonal centers")

plt.savefig("tonic.png")
plt.close()
#+end_src

#+RESULTS:
[[file:tonic.png]]

** Graphs

#+begin_src python :results output
continent_counts = Counter()

for f in ESSEN_ROOT.rglob("*.krn"):
    continent = f.parts[2] if len(f.parts) > 2 else "unknown"
    continent_counts[continent] += 1

print(continent_counts)
#+end_src

#+RESULTS:
: Counter({'europa': 6213, 'asia': 2246, 'america': 13, 'africa': 1})


#+begin_src python :results file graphics :file melody_lengths.png
files = sorted(ESSEN_ROOT.rglob("*.krn"))
lengths = [len(load_kern_melody(f)) for f in files]

# plt.hist(lengths, bins=50)
# plt.xlabel("Number of events per melody")
# plt.ylabel("Count")
# plt.title("Melody length distribution (Essen corpus)")
# plt.show()


df = pd.DataFrame({"length": lengths})

plt.figure(figsize=(10,7))
sns.histplot(df["length"], bins=50, kde=True)
plt.xlabel("Number of events per melody")
plt.ylabel("Count")
plt.title("Melody length distribution (Essen corpus)")
plt.tight_layout()

plt.savefig("melody_lengths.png")
plt.close()
#+end_src

#+RESULTS:
[[file:melody_lengths.png]]

#+begin_src python :results output
print("median:", np.median(lengths))
print("mean:", np.mean(lengths))
print("max:", max(lengths))
#+end_src

#+RESULTS:
: median: 48.0
: mean: 54.80266729611708
: max: 520

#+begin_src python :results output
pitch_counter = Counter()

for f in files:
  for event in load_kern_melody(f):
    if not event.is_rest:
      pitch_counter[event.pitch] += 1

print("Unique pitches:", len(pitch_counter))
pitch_counter.most_common(20)
#+end_src

#+RESULTS:
: Unique pitches: 114

#+begin_src python :results file graphics :file pitch_freq.png
# plt.figure(figsize=(10,4))
# labels, values = zip(*pitch_counter.most_common(30))
# plt.bar(labels, values)
# # plt.xticks(rotation=90)
# plt.title("Most frequent pitches")
# plt.tight_layout()

# plt.savefig("pitch_common.png")
# plt.close()

df = (
    pd.DataFrame(pitch_counter.items(), columns=["pitch", "count"])
    .sort_values("count", ascending=False)
    .head(30)
)

plt.figure(figsize=(10,6))
sns.barplot(data=df, x="pitch", y="count", palette="viridis")
plt.xticks(rotation=90)
plt.title("Most frequent pitches (top 30)")
plt.tight_layout()

plt.savefig("pitch_freq.png")
plt.close()
#+end_src

#+RESULTS:
[[file:pitch_freq.png]]


#+begin_src python :results file graphics :file rhythm_freq.png
dur_counter = Counter()

for f in files:
    for ev in load_kern_melody(f):
        dur_counter[ev.duration] += 1

df = (
    pd.DataFrame(dur_counter.items(), columns=["duration", "count"])
      .sort_values("count", ascending=False)
      .head(20)
)

plt.figure(figsize=(12, 5))

sns.barplot(
    data=df,
    x="duration",
    y="count",
    palette="viridis"
)

plt.title("Most frequent rhythmic durations (Essen corpus)")
plt.xlabel("Duration (kern reciprocal notation)")
plt.ylabel("Count")
plt.tight_layout()
plt.savefig("rhythm_freq.png", dpi=200)
plt.close()
#+end_src

#+RESULTS:
[[file:rhythm_freq.png]]

#+begin_src python :results file graphics :file rhythm_by_continent.png
rows = []

for f in files:
    continent = f.parts[2]
    for ev in load_kern_melody(f):
        rows.append((continent, ev.duration))

df = pd.DataFrame(rows, columns=["continent", "duration"])

plt.figure(figsize=(12,5))
sns.countplot(
    data=df,
    x="duration",
    hue="continent",
    order=df["duration"].value_counts().index[:10],
    palette="viridis"
)

plt.figure(figsize=(8,4), dpi=120)
sns.countplot(
    data=df,
    x="duration",
    hue="continent",
    order=df["duration"].value_counts().index[:10],
    palette="viridis"
)
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("rhythm_by_continent.png", dpi=120, bbox_inches="tight")
plt.close()
#+end_src

#+RESULTS:
[[file:rhythm_by_continent.png]]


#+begin_src python :results file graphics :file rhythm_norm_continent.png
rows = []

for f in files:
    durations = [ev.duration for ev in load_kern_melody(f)]
    total = len(durations)
    for d in durations:
        rows.append((f.parts[2], d, 1/total))

df = pd.DataFrame(rows, columns=["continent", "duration", "weight"])

plt.figure(figsize=(12,5))
sns.barplot(
    data=df,
    x="duration",
    y="weight",
    hue="continent",
    estimator=sum,
    palette="viridis"
)

plt.title("Normalized rhythmic distribution per continent")
plt.tight_layout()
plt.savefig("rhythm_norm_continent.png", dpi=100, bbox_inches="tight")
plt.close()
#+end_src

#+RESULTS:
[[file:rhythm_norm_continent.png]]

* Preparing final data structure for training

We will start with focusing on the pitch as the basic viewpoint to take into consideration
since it is one the most representative viewpoints on IDyOM, as well as one of the most
representative attributes of a note.

For that, we would need to change the krn notation into smth that Transformers can manipulate.
The most efficient way is transforming them into integers, that can be the abc notation or the
Midi notation. This would a very easy task since we can use the library =music21=

However, krn notatation uses n when mentioning a natural note after an altered note, something
that =music21= does not understand when parsing the pitch. Another issue are repeated letters,
as previously explained, these symbolise octaves. One way to solve this would be to convert the
kern file into a midi file:

#+begin_src python :results output
from music21 import converter

score = converter.parse("data/essen/europa/misc/island02.krn")

score.write("midi", fp="island02.midi")
#+end_src

But this way gives us a bit of a round path since we would then need to parse the midi file
and then finally extract the pitch numbers. Instead, we can create some rules in order for
music21's Pitch function can properly recognise the pitch values in kern and correctly parse
them into midi values (integers).

Rests are also not included in midi notation, so for now we can keep only the notes that are
not a rest. Luckily, we already accounted for this when loading and cleaning the Essen corpus,
therefore we just need to keep those rows that are not a rest, that is that contain a False
in the "is_rest" column.

There are also other edge cases that music21 does not recognise in the kern notation, so we
can do a manual mapping to avoid having any missing notes or errors when parsing the corpus. 

#+begin_src python :results output
def kern_to_midi(k_pitch):
    note_map = {'c': 0, 'd': 2, 'e': 4, 'f': 5, 'g': 7, 'a': 9, 'b': 11}
    
    letter = k_pitch[0].lower()
    
    if k_pitch[0].islower():
        # count consecutive repetitions of the letter
        count = 0
        for ch in k_pitch:
            if ch.lower() == letter:
                count += 1
            else:
                break
        # c=4 and cc=5
        octave = 3 + count
    else:
        count = 0
        for ch in k_pitch:
            if ch.upper() == k_pitch[0]:
                count += 1
            else:
                break
        # C=3 and CC=2
        octave = 4 - count
    
    midi = 12 * (octave + 1) + note_map[letter]
    
    # accidentals after the letters
    remainder = k_pitch[count:]
    midi += remainder.count('#')
    midi -= remainder.count('-')
    # 'n' = natural, no change
    
    return midi
#+end_src

#+RESULTS:

#+begin_src python :results output
df_notes = df_vp[df_vp["is_rest"] == False].drop(["is_rest"], axis=1).copy()
df_notes["midi_pitch"] = df_notes["pitch"].apply(kern_to_midi)
#+end_src

#+RESULTS:

#+begin_src python :results output
print(df_notes.sample(10))
#+end_src

#+RESULTS:
#+begin_example
            filename                                            path continent   country  length  melody_id  position pitch duration  midi_pitch
132575  deut5066.krn  data/essen/europa/deutschl/zuccal/deut5066.krn    europa  deutschl      69       2597        21     g       16          67
209151  deut1358.krn     data/essen/europa/deutschl/erk/deut1358.krn    europa  deutschl      67       4145        12     b        8          71
225378  deut1648.krn     data/essen/europa/deutschl/erk/deut1648.krn    europa  deutschl      41       4478        20    cc        4          72
383782   han0120.krn           data/essen/asia/china/han/han0120.krn      asia     china     215       7399       142    dd       16          74
387336   han0900.krn           data/essen/asia/china/han/han0900.krn      asia     china     103       7439        54    gg       16          79
76469   deut2732.krn  data/essen/europa/deutschl/boehme/deut2732.krn    europa  deutschl      66       1513        64     d        4          62
369290   han1071.krn           data/essen/asia/china/han/han1071.krn      asia     china     166       7228       140     c        8          60
144898  deut4523.krn  data/essen/europa/deutschl/zuccal/deut4523.krn    europa  deutschl      86       2827        84     c        4          60
359417   han0195.krn           data/essen/asia/china/han/han0195.krn      asia     china     171       7085        55    dd       16          74
132430  deut5080.krn  data/essen/europa/deutschl/zuccal/deut5080.krn    europa  deutschl      56       2594        51     g        8          67
#+end_example
