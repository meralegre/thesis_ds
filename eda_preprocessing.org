#+TITLE: EDA & Preprocessing of Musical Corpus
#+AUTHOR: Maria Gonzalez Alegre
#+DATE: 2025-12-31

#+PROPERTY: header-args:python :results output :exports results :eval yes

* Introduction
* Conclusion
* Manual Preprocessing
** Imports

#+begin_src python :results silent
import pandas as pd
import numpy as np

import re
import zipfile
import pathlib
import random
from pathlib import Path
from typing import List, Optional
from dataclasses import dataclass
from collections import Counter

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import seaborn as sns
sns.set_theme(
    style="whitegrid",
    context="talk",
)
#+end_src

** Kern syntax

In the Humdrum syntax, columns of data are called SPINES. SPINES of information may change
position within a file; they may disappear, or split into several columns, for example.

Based on the information found in the Github repo with the Essen files [cite], the music files contain
several indicators that need to be taken into account:

*** INTERPRETATIONS
  Labels that indicate the tyoe of information being represented in each Spine. They are
  represented as two asterisks (**). We also have *SPINE-PATH TERMINATORS*, they indicate the end
  of their respective spine, represented as *-

*** TANDEM INTERPRETATIONS
  Tandem interpretations are identified by a single leading asterisk (*).
  Tandem interpretations encode additional or supplementary information, for example the names
  of the voices

*** COMMENTS
  In any representation, some information may best be conveyed as
  COMMENTS rather than as part of the encoded data. In Humdrum formats they are expressed as
  exclamation marks:
  - *GLOBAL COMMENTS*: they begin with two exclamation marks
  - *LOCAL COMMENTS*: they begin with one exclamation mark
  - *NULL LOCAL COMMENTS*: exclamation marks with no text

*** PITCH
  Enconded through a scheme of upper and lower case letters:
  - c      middle C (i.e. C4)
  - cc     C an octave higher than middle C (C5)
  - C      C an octave lower than middle C (C3)
  - CC     C two octaves lower than middle C (C2)
  - B      B below middle C (B3)
  - b      B a major seventh above middle C (B4)
  - d#     D-sharp above middle C (D#4)
  - d##    D double-sharp above middle C
  - d###   D tiple-sharp above middle C
  - e-     E-flat above middle C (enharmonically equivalent to d##)
  - BB--   B double-flat; augmented ninth below middle C
  - cn     C natural, middle C

  Sharps, flats, and naturals are mutually exclusive in **kern, so tokens such as "cc#n" and
  "GG-#" are illegal. Something to take into account when cleaning the data, in case some errors
  are present.

*** SLURS, TIES, PHRASES
  - *Phrases*: indicated by {}
  - *Slurs*: indicated by () --> ligadura entre notas distintas
  - *Ties*: indicated by [] --> ligadura entre misma nota

  They can be nested and elided (the overlapping of phrases, where the last note or chord
  of one phrase serves simultaneously as the first note or chord of the next)

*** ORNAMENTS
  - "T" and "t": whole-tone and semitone TRILLS
  - "M" and "m": whole-tone and semitone MORDENTS
  - "W" and "w": whole-tone and semitone INVERTED MORDENTS
  - "S":  a TURN
  - dollar sign ("$"): an inverted (or Wagnerian) TURN
  - "R":  When a concluding turn is appended to the end of an ornament, "R" is
    added to the ornament signifier (as in "tR" and "TR").
  - ":" (multi-note) ARPEGGIATION
  - "0": presence of ornaments OTHER than trills, mordents, inverted mordents, and turns.

*** ARTICULATION MARKS
  - (') for STACCATO
  - double-quote (") for PIZZICATO
  - greve (`) for ATTACCA
  - tilde (~) for TENUTO
  - caret (^) for all note-related accents (including < and >)

*** UP & DOWN BOWS
  - up-bow (v) and down-bow (u)

*** STEMS (plica)
  - "/": Up-stem
  - "\": Down-stem

*** DURATIONS
  0       breve duration (redonda)
  1       whole duration
  2       half duration
  4       quarter duration
  8       eighth duration
  16      sixteenth duration
  32      thirty-second duration
  64      sixty-fourth duration

  *Dotted notes*:
    2.	dotted half duration
    8..	doubly-dotted eighth duration

  The semicolon (;) denotes a pause.

*** GRACE NOTES & GROUPETTOS
  - *ACCIACCATURAS*: "q", e.g "G#q"
  - *GROUPETTOS*: "Q", e.g minature sixteenth-note middle C would be encoded as "16cQ"
  - *APPOGGIATURAS*: The appoggiatura note itself is designated by the upper-case letter "P", whereas
    the subsequent note (whose notated duration has been shorted) is designated by the
    lower-case letter "p".

*** BEAMING
  - beginning and ends of beams are signified by the upper-case letters
    "L" and "J" respectively
  - Partial beams may extend to the right (K) or left (k)
  - each beam is designated by its own L-J pair, e.g:
    16..LL
    64JJkk
 
*** BARLINES
   0-9	measure numbers
   a-z	alternate measures
   ;	pause
   =	barline
   ==	double barline
   |	normal width visual rendering
   !	heavy width visual rendering
   '	partial barline (from second to fourth line)
   `	partial barline (short stroke at top of staff)
   -	invisible barline
   :	repeat sign

**** Examples
     =	        unnumbered barline
     =29 	the beginning of measure 29
     =29; 	the beginning of measure 29 with pause
     =29a	first occurrence of measure 29
     =29c	third occurrence of measure 29
     =29c;	third occurrence of measure 29 with pause
     ==	        double barline
     ==;	double barline with pause
     =|	        unnumbered barline, normal line width
     =!	        unnumbered barline, heavy line width
     ==|!	double barline, normal line followed by heavy line
     =29|	beginning of measure 29, normal line width
     =:|:	barline with left and right repeats, normal line width
     =:||:	barline with left and right repeats, two normal-width lines
     ='	        unnumbered barline, rendered with partial barline (mid)
     =29`	beginning of measure 29, rendered with partial barline (top)
     =29-	beginning of measure 29, no barline drawn
     ==:|!	double barline with repeat, normal/heavy lines
     ==|	logical double barline, visually rendered as single normal line
     |	        not a barline
     29|	not a barline

*** TABLE OF SIGNIFIERS
	0       breve duration
	1       whole duration
	2       half duration
	3       half-note triplet duration
	4       quarter duration
	6       quarter-note triplet duration
	8       eighth duration
	12      eighth-note triplet duration
	16      sixteenth duration
	24      sixteenth-note triplet duration
	32      thirty-second duration
	64      sixty-fourth duration
	128     one-hundred and twenty-eighth duration
	.       duration augmentation dot (must follow a number)
	-       flat sign (minus character)
	--      double-flat (two successive minus characters)
	a-g     absolute pitches above middle C
	A-G     absolute pitches below middle C
	#       sharp
	##      double sharp
	h       end glissando
	j       harmonic
	k       partial beam extending leftward
	kk      two partial beams extending leftward
	m       mordent (semitone)
	n       natural sign
	p       designator of a note subsequent to an appoggiatura
	q       acciaccatura (grace note signifier; in lieu of duration)
	r       rest
	t       trill (semitone)
	u       down-bow
	v       up-bow
	w       inverted mordent (semitone)
	x       editorial interpretation; immediately preceding signifier is
                  interpreted
	xx      editorial interpretation; entire data token is interpreted
	y       editorial mark:  invisible symbol; unprinted note-, rest-, or
	          barline-attribute, but logically implied
	yy      editorial mark:  invisible symbol; unprinted note, rest, or
	          barline, but logically implied
	z       sforzando
	H       begin glissando
	I       generic articulation (unspecified articulation)
	J       end beam
	JJ      end two beams
	K       partial beam extending rightward
	KK      two partial beams extending rightward
	L       start beam
	LL      start two beams
	M       mordent (whole tone)
	O       generic ornament (unspecified ornament)
	P       appoggiatura note designator
	Q       groupetto note designator
	R       signified ornament ends with a turn
	S       turn
	$       Wagnerian turn
	T       trill (whole tone)
	W       inverted mordent (whole tone)
	X       editorial intervention; immediately preceding signifier is an
	          editorial addition
	XX      editorial intervention; entire data token is an editorial
                  addition
	Y       editorial mark:  sic marking; information is encoded
	          literally, but is questionable
	YY      editorial mark:  sic marking; entire data token is encoded
	          literally, but is questionable
	<space> (space character) multiple-stop conjunction -- indicates
	        joint note-tokens
	=       barline; == double barline
	[       first note of a tie
	]       last note of a tie
	_       middle note(s) of a tie (underscore)
	(       slur start
	)       slur end
	{       phrase mark (start)
	}       phrase mark (end)
	;       pause sign
	'       staccato mark
	s       spiccato
	"       pizzicato mark
	`       attacca mark
	~       tenuto mark
	^       accent mark
	:       arpeggiation (of multi-note chord)
	,       breath mark
	/       up-stem
	\       down-stem
	&       elision marker (for slurs or phrases)
	?       editorial mark: immediately preceding signifier has accompanying
	          editorial footnote
	??      editorial mark: entire preceding data token has accompanying
	          editorial footnote

*** SUMMARY

| signified                           | signifier(s)        | comments                     |
|-------------------------------------+---------------------+------------------------------|
| 1. open phrase elision indicator    | &                   | must precede {               |
| 2. open phrase mark                 | {                   |                              |
| 3. open slur elision indicator      | &                   | must precede (               |
| 4. open slur                        | (                   |                              |
| 5. open tie                         | [                   |                              |
| 6. duration                         | 0123456789          | any combination; signifiers  |
| may be repeated                     |                     |                              |
| 7. augmentation dot(s)              | .                   | signifier may be repeated    |
| 8. pitch                            | abcdefgABCDEFG      | only one of; signifier may   |
| be repeated                         |                     |                              |
| 9. accidental                       | - or # or n         | - and # may be repeated      |
| 10. pause                           | ;                   |                              |
| 11. ornament                        | MmS$TtWwR or O      | O precludes others; no repe- |
| tition of a given signifier;        |                     |                              |
| must appear in order given          |                     |                              |
| 12. appoggiatura designator         | p or P              |                              |
| 13. acciaccatura designator         | q                   |                              |
| 14. groupetto designator            | Q                   |                              |
| 15. articulation                    | z ' " ` ~ ^ : or I  | I precludes others; no re-   |
| petition of a given signifier;      |                     |                              |
| must appear in order given          |                     |                              |
| 16. bowing                          | u or v              | only one of                  |
| 17. stem-direction                  | / or \              | only one of                  |
| 18. beaming                         | L or J              | signifiers may be repeated   |
| 19. partial beaming                 | k or K              | signifiers may be repeated   |
| 20. user-defined marks              | il                  | one or more of;              |
| NUVZ                                | may be repeated but |                              |
| @ % +                               | < >                 | must be in order given       |
| 21. closed or continuing tie        | ] or _              |                              |
| 22. closed slur elision indicator   | &                   | must precede )               |
| 23. closed slur                     | )                   |                              |
| 24. closed phrase elision indicator | &                   | must precede }               |
| 25. closed phrase mark              | }                   |                              |
| 26. breath mark                     | ,                   |                              |
| 27. editorial marks                 | xx or XX            |                              |
| 28. editorial marks                 | yy or YY            |                              |
| 29. editorial marks                 | ??                  |                              |
|                                     |                     |                              |

** Essen Folksongs Data

#+begin_src python :results silent
ESSEN_ROOT = pathlib.Path("data/essen")

ESSEN_REGIONS = ["europa", "asia", "africa", "america"]
#+end_src

** Parsing decisions and functions
<<sec:parsing>>
According to the =**kern= specification, each token consists of a combination of signifiers
encoding duration, pitch, accidentals, rests, ornaments, articulation, beaming, editorial
marks, and other information.

For the purpose of melodic expectation modeling, we define *musical events* as
notes and rests with the following properties:

- *Kept information*:
  - Duration digits and dots (=0–9= and =.=).
  - Pitch letters (=a–g= / =A–G=) and accidentals (_ =, =-=, =#=, =n=).
  - Rest marker =r= (and potentially pause =;=) to represent silence.

- *Removed information*:
  - Ornaments (trills, mordents, turns, etc.).
  - Appoggiaturas, acciaccaturas (grace notes), and groupettos.
  - Articulation, bowing, stem direction, beaming, partial beaming.
  - User-defined and editorial marks.

This follows the manual’s distinction between core syntactic information and
decorative or editorial notation and matches common practice in IDyOM-style
melodic modeling where durationless ornaments and purely notational details
are excluded from the event stream.

#TODO:
GROUPING_CHARS: 

*** Elements definitions
#+begin_src python :results silent
# Core signifier sets
DURATION_CHARS = set("0123456789.")
PITCH_CHARS = set("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ")
ACCIDENTAL_CHARS = set("_-#n")
REST_CHAR = "r"
PAUSE_CHAR = ";"
GROUPING_CHARS = set("{}()[]")

# Non-core signifiers (to be removed)
ORNAMENT_CHARS = set("Mm$STtwWRO")     # ornaments
APPOGGIATURA_CHARS = set("pP")          # appoggiaturas
GRACE_CHAR = "q"                        # acciaccaturas
GROUPETTO_CHAR = "Q"                    # groupettos
ARTICULATION_CHARS = set("z'\"`^~:I")   # articulations
BOWING_CHARS = set("uv")                # bowing positions
STEM_DIR_CHARS = set("/\\")             # stem direction
BEAM_CHARS = set("LJ")                  # beaming
PARTIAL_BEAM_CHARS = set("kK")          # partial beaming
EDITORIAL_CHARS = set("xXyY?")          # editorial marks
USER_MARK_CHARS = set("iltNUVZ@%+")     # user-defined marks

NON_CORE_CHARS = (
    ORNAMENT_CHARS
    | APPOGGIATURA_CHARS
    | ARTICULATION_CHARS
    | BOWING_CHARS
    | STEM_DIR_CHARS
    | BEAM_CHARS
    | PARTIAL_BEAM_CHARS
    | EDITORIAL_CHARS
    | USER_MARK_CHARS
)
#+end_src

*** Helper functions
<<sec:helper>>
Above we defined which elements and characters are core for the analysis and processing
of data in order to prepare it for modelling. In this section we will define helper functions
to recognise said characters and clean the =**kern= files to prepare them for EDA and modelling.

Instead of directly defining a helper function for each unnecessary element in the data, we
just focus for now on null tokens and durationless ornaments that were defined previously to
avoid overcrowding later on the full cleaning function. Elements such as interpretations,
tandems and comments are easily included in the bigger function, having small helper functions
would be a good addition but it is not necessary for such small elements.

Since these do not represent musical events, we do not need to include them in the process.
Better skip them now to avoid unnecessary elements in the data.

Even though for a more detailed and elaborate study of the musical data elements such as
acciaturas and groupettos might be useful and interesting, we will opt to remove them for now.
In case we want to work with their inclusion later on, we can simply rerun the cleaning of
the data without the removal of these characters.

#+begin_src python :results silent
def is_null_token(line):
  return line.startswith(".")

def has_grace_or_groupetto(tok: str) -> bool:
  # Durationless ornaments that should not be counted as events.
  return (GRACE_CHAR in tok) or (GROUPETTO_CHAR in tok)
#+end_src

We will stript all ornaments, bowing, stems, beamings and editorial marks as well to leave only
the minimal syntactic information needed to define duration and pitch (including rests).
This way we focus on structural melodic content rather than detailed notations. 

#+begin_src python :results silent
def strip_non_core_signifiers(tok: str) -> str:
    """
    Remove ornaments, articulation, beams, editorial marks and other
    non-core signifiers, preserving duration, pitch, accidentals and rest.
    """
    return "".join(ch for ch in tok if ch not in NON_CORE_CHARS)
#+end_src

*** Parsing tokens

The =parse_kern_token= function is the main function for the parsing process.
It gathers the previous helper functions defined above in order to create a single
=**kern= token into KernEvents.
Why do we create a class for this?
- We want to turn messy tokens into a structured, clean and homogenous event that will make it easier
  to analyse and feed the models later on.

In this section, we focus on the cleaning of the data. Ornaments and editorial notations are not
necesary for our purpose and will just end up creating noise for the ultimate modelling section. 

#+begin_src python :results output
@dataclass
class KernEvent:
    duration: str
    pitch: str
    is_rest: bool


def parse_kern_token(tok: str) -> Optional[KernEvent]:
    tok = tok.strip()
    if not tok or is_null_token(tok):
        return None
    if has_grace_or_groupetto(tok):
        return None

    tok = strip_non_core_signifiers(tok)

    # strip grouping / phrasing markers that can wrap tokens
    while tok and tok[0] in GROUPING_CHARS:
        tok = tok[1:]
    while tok and tok[-1] in GROUPING_CHARS:
        tok = tok[:-1]
    if not tok or is_null_token(tok):
        return None

    # Extract duration (leading digits + dots)
    i = 0
    dur_chars = []
    while i < len(tok) and tok[i].isdigit():
        dur_chars.append(tok[i])
        i += 1
    while i < len(tok) and tok[i] == ".":
        dur_chars.append(tok[i])
        i += 1
    duration = "".join(dur_chars)
    if not duration:
        return None

    pitch_part = tok[i:]
    if not pitch_part:
        return None

    is_rest = (REST_CHAR in pitch_part) or (PAUSE_CHAR in pitch_part)
    if is_rest:
        pitch_norm = "r"
    else:
        pitch_chars = [ch for ch in pitch_part if ch in PITCH_CHARS or ch in ACCIDENTAL_CHARS]
        if not pitch_chars:
            return None
        pitch_norm = "".join(pitch_chars)

    return KernEvent(duration=duration, pitch=pitch_norm, is_rest=is_rest)

#+end_src

#+RESULTS:

**** Example

#+BEGIN_SRC python :results output
# Some example **kern note tokens, including ornaments and rests.
tokens = [
    "4c",          # quarter-note C
    "8g#",         # eighth-note G sharp
    "4cL",         # quarter-note C with beaming (L) that should be stripped
    "16bq",        # grace-note B (q) that should be discarded entirely
    "8.cc#",       # dotted eighth-note C-sharp
    "4r",          # quarter rest
    "4G$'",        # quarter-note G with ornament ($) and articulation (') to drop
    ".",
]

for tok in tokens:
    ev = parse_kern_token(tok)
    print(f"token={tok!r} ->", ev)
#+END_SRC

#+RESULTS:
: token='4c' -> KernEvent(duration='4', pitch='c', is_rest=False)
: token='8g#' -> KernEvent(duration='8', pitch='g#', is_rest=False)
: token='4cL' -> KernEvent(duration='4', pitch='c', is_rest=False)
: token='16bq' -> None
: token='8.cc#' -> KernEvent(duration='8.', pitch='cc#', is_rest=False)
: token='4r' -> KernEvent(duration='4', pitch='r', is_rest=True)
: token="4G$'" -> KernEvent(duration='4', pitch='G', is_rest=False)
: token='.' -> None

** Loading and cleaning the Essen corpus
This section walks over the Essen folder structure (grouped by country/region),
parses each file using the token‑level rules above.
The result is a list of cleaned event sequences with metadata.

We loop over each region found in the Essen data folder. For each folder we recursively
find all Humdrum =**kern= files.
This function was mainly created to check whether all the files were available and selectable for
for the next steps of the project. Based on our results, the files are readable and can be used
for further processing. 

#+begin_src python :results silent
def iter_essen_files():
    """
    Yield (path,) for every .krn file anywhere under data/essen.
    """
    for path in ESSEN_ROOT.rglob("*.krn"):
        yield path
#+end_src

#+begin_src python :results output
files_seen = list(iter_essen_files())
print("Files seen:", len(files_seen))
#+end_src

#+RESULTS:
: Files seen: 8473

#+begin_src python :results output
for i, p in enumerate(iter_essen_files()):
    print(i, "->", p)
    if i == 9:
        break
#+end_src

#+RESULTS:
#+begin_example
0 -> data/essen/europa/misc/island02.krn
1 -> data/essen/europa/misc/steier01.krn
2 -> data/essen/europa/misc/norge02.krn
3 -> data/essen/europa/misc/island01.krn
4 -> data/essen/europa/misc/ellas01.krn
5 -> data/essen/europa/misc/steier03.krn
6 -> data/essen/europa/misc/steier02.krn
7 -> data/essen/europa/misc/norge01.krn
8 -> data/essen/europa/misc/steier06.krn
9 -> data/essen/europa/misc/emmenth1.krn
#+end_example


After obtaining the =**kern= files, we need to extract from the full file the musical
representations that we need for future training as explained in the [[sec:parsing][parsing section]]
and the [[sec:helper][helper functions]] definition.
This way, we apply the classification rules from the Humdrum spec:
We skip empty lines and the following attributes:
- global and local comments
- interpretation lines that declare spyne types
- tandem interpretations (e.g., name of voices)
- barlines

With this function we apply the cleaning previously defined with =parse_kern_tokens= on
the full Humdrum file. 

For the remaining lines, we split the data on tab and take the first token, assuming monophonic
melodies and one relevant spine per file (which is how Essen is structured for melodic analysis)

#+begin_src python :results output
def load_kern_melody(path: pathlib.Path):
    out = []
    raw_tokens = 0
    parsed_tokens = 0

    with path.open("r", encoding="utf-8", errors="ignore") as f:
        for raw in f:
            line = raw.strip()
            if not line:
                continue

            if line.startswith(("*", "!", "=", ".")):
                continue

            tok = line.split("\t")[0].strip()
            raw_tokens += 1

            ev = parse_kern_token(tok)
            if ev is not None:
                out.append(ev)
                parsed_tokens += 1

    return out

test_path = pathlib.Path("data/essen/europa/misc/island02.krn")
events = load_kern_melody(test_path)
print("EVENTS:", len(events))
for i, ev in enumerate(events[:10]):
    print(i, ev)
#+end_src

#+RESULTS:
#+begin_example
EVENTS: 48
0 KernEvent(duration='8.', pitch='a', is_rest=False)
1 KernEvent(duration='16', pitch='b', is_rest=False)
2 KernEvent(duration='8', pitch='ccn', is_rest=False)
3 KernEvent(duration='8.', pitch='b', is_rest=False)
4 KernEvent(duration='16', pitch='a', is_rest=False)
5 KernEvent(duration='8', pitch='g#', is_rest=False)
6 KernEvent(duration='8.', pitch='a', is_rest=False)
7 KernEvent(duration='16', pitch='b', is_rest=False)
8 KernEvent(duration='8', pitch='ccn', is_rest=False)
9 KernEvent(duration='4', pitch='b', is_rest=False)
#+end_example

Now, as the last step, we build the full clean corpus.
This function iterates over each file (as shown before all files are captured).
For each file, we obtain its events with the previously defined =load_kern_melody= function.
After obtaining the files, we derive a simple contry label from the path by taking the second
element of the relative path. This way we can group the results based on the countries and regions.

The function returns two lists, the =melodies= with the events (KernEvent) from each melody.
And second, the =meta_list= contains the metadata from each file, that is its name, path, region,
country and length of the melody. 

#+begin_src python :results silent
MIN_EVENTS = 20

def collect_clean_essen():
    melodies = []
    meta_list = []

    for path in ESSEN_ROOT.rglob("*.krn"):
        events = load_kern_melody(path)
        # if len(events) < MIN_EVENTS:
        #     continue

        # derive region/country from relative path
        rel_parts = path.relative_to(ESSEN_ROOT).parts
        region = rel_parts[0] if len(rel_parts) > 0 else "unknown"
        country = rel_parts[1] if len(rel_parts) > 1 else "unknown"

        melodies.append(events)
        meta_list.append({
            "filename": path.name,
            "path": str(path),
            "region": region,
            "country": country,
            "length": len(events),
        })
    return melodies, meta_list
#+end_src

#+begin_src python :results output
melodies, meta = collect_clean_essen()
print("Number of melodies:", len(melodies))
#+end_src

#+RESULTS:
: Number of melodies: 8473

Let's inspect some of the melodies
#+begin_src python :results output
idxs = random.sample(range(len(meta)), 20)
for i in idxs:
    print(i, meta[i]["region"], meta[i]["country"], meta[i]["filename"], "len:", meta[i]["length"])
#+end_src

#+RESULTS:
#+begin_example
5152 europa deutschl deut028.krn len: 51
1971 europa deutschl deut5132.krn len: 28
482 europa deutschl deut3296.krn len: 26
6659 asia china shanx318.krn len: 36
2223 europa deutschl deut3845.krn len: 35
7924 asia china han0689.krn len: 78
6063 europa jugoslav jugos042.krn len: 18
6491 asia china shanx264.krn len: 24
341 europa deutschl deut4097.krn len: 42
7336 asia china han0147.krn len: 128
5895 europa elsass elsass21.krn len: 57
7406 asia china han0861.krn len: 64
1832 europa deutschl kindr203.krn len: 56
648 europa deutschl deut3385.krn len: 34
2942 europa deutschl deut1120.krn len: 34
7464 asia china han0341b.krn len: 49
4841 europa deutschl deut247.krn len: 80
3065 europa deutschl deut0759.krn len: 42
8119 asia china han0010.krn len: 23
3850 europa deutschl deut1956.krn len: 51
#+end_example

#+begin_src python :results output
m0 = melodies[0]
print("First melody: length", len(m0))
print("First 10 events:")
for i, ev in enumerate(m0[:10]):
    print(i, ev)
#+end_src

#+RESULTS:
#+begin_example
First melody: length 48
First 10 events:
0 KernEvent(duration='8.', pitch='a', is_rest=False)
1 KernEvent(duration='16', pitch='b', is_rest=False)
2 KernEvent(duration='8', pitch='ccn', is_rest=False)
3 KernEvent(duration='8.', pitch='b', is_rest=False)
4 KernEvent(duration='16', pitch='a', is_rest=False)
5 KernEvent(duration='8', pitch='g#', is_rest=False)
6 KernEvent(duration='8.', pitch='a', is_rest=False)
7 KernEvent(duration='16', pitch='b', is_rest=False)
8 KernEvent(duration='8', pitch='ccn', is_rest=False)
9 KernEvent(duration='4', pitch='b', is_rest=False)
#+end_example

#+begin_src python :results output
# Explode: one row per KernEvent
events_df = []
for i, (events, m) in enumerate(zip(melodies, meta)):
    for j, ev in enumerate(events):
        row = m.copy()
        row.update({
            'melody_id': i,
            'position': j,
            'pitch': ev.pitch,
            'duration': ev.duration,
            'is_rest': ev.is_rest
        })
        events_df.append(row)

df = pd.DataFrame(events_df)
print(df.shape)
print(df.sample(5))
#+end_src

#+RESULTS:
: (464343, 10)
:             filename                                            path  region   country  length  melody_id  position pitch duration  is_rest
: 330149  shanx116.krn       data/essen/asia/china/shanxi/shanx116.krn    asia     china      63       6505        42     c        2    False
: 440788   han0428.krn           data/essen/asia/china/han/han0428.krn    asia     china      96       8135        49     c       8.    False
: 281941  france01.krn           data/essen/europa/france/france01.krn  europa    france     139       5452        95     d        2    False
: 35927   deut3562.krn  data/essen/europa/deutschl/ballad/deut3562.krn  europa  deutschl      30        772         0     c        8    False
: 305267  elsass61.krn           data/essen/europa/elsass/elsass61.krn  europa    elsass      82       5953        70     e        4    False

* Humdrum Tools
** Extracting and cleaning melodies

The Humdrum data type counts as well with its tool kit that allows for the inspection and
cleaning of raw =**kern= files. It is interesting to use it to double check wheter the manual
preprocessing done is correct. Based on the results, the data obtained from the files corresponds
to what is obtained from the Kumdrum files.

This code block does the following:
- rid removes interpretive data, that is, it strips non-musical lines from Humdrum files.
- G removes global comments
- L removes local comments
- I removes interpretations

Next, =awk -F'\t' '{print $1}'= takes care of selecting only the first spine of the kern file,
that is, in case we have any polyphonies on our corpus, it will be turned into a monophony by
solely selecting the first voice (spine). The field separator (F) is set to tabs, since that is
the standard separations on kern files.

Finally, we get rid of the barlines, as explained before, they offer no musical information, they
are just structural separators that do not bring meaninful information for future modelling. 

#+begin_src bash :results output
rid -GLI data/essen/europa/misc/island01.krn \
  | awk -F'\t' '{print $1}' \
  | grep -v '^=' \
  > /tmp/island02.tokens

head -n 20 /tmp/island02.tokens
#+end_src

#+RESULTS:
#+begin_example
{4.cc
16cc
16cc
4.cc
8cc
8cc
8b
4a
2g}
{4g
4g
4.g
8g
2b-
4a
4r}
{4.cc
8cc
4.cc
8cc
#+end_example

* EDA
** Melody inspection

Even though on our cleaning and preprocessing steps we immediately applied the selection of only
one voice, it is interesting to check whether any of our songs are actually polyphonic.

Based on the results with python and Humdrum tools, all of our melodies are monophonic, which
makes the processing much easier. 

#+begin_src bash :results output
find data/essen -name "*.krn" | while read f; do
  grep -m 1 '^\*\*' "$f" | awk -F'\t' '{print NF}'
done | sort | uniq -c
#+end_src

#+RESULTS:
: 8473 1

#+begin_src python :results output
voice_counts = {}

for f in Path("data/essen").rglob("*.krn"):
    with f.open(encoding="utf-8", errors="ignore") as fh:
        for line in fh:
            if line.startswith("**"):
                n_voices = line.count("\t") + 1
                voice_counts[n_voices] = voice_counts.get(n_voices, 0) + 1
                break

for k in sorted(voice_counts):
    print(f"{k} voices: {voice_counts[k]} files")
#+end_src

#+RESULTS:
: 1 voices: 8473 files

** Obtaining keys

#+begin_src bash :results output
key data/essen/europa/misc/island02.krn
#+end_src

#+RESULTS:
: Estimated key: A minor	(r=0.6230)	confidence:	42.6%

#+begin_src bash :results output
mkeyscape -ln data/essen/europa/misc/island01.krn | magick - ./island01_key.png
#+end_src

#+RESULTS:

*** Keys from the kern notation

#+begin_src python :results output
key_tandem_re = re.compile(r'^\*[A-Ga-g](?:#|-)?\s*:\s*$', re.M)
ksig_re = re.compile(r'^\*k\[[^\]]*\]\s*$', re.M)

def first_matches(path: Path=ESSEN_ROOT):
    files = sorted(path.rglob("*.krn"))
    data = []
    for f in files:
        txt = f.read_text(encoding="utf-8", errors="ignore")
        key_m = key_tandem_re.search(txt)
        ksig_m = ksig_re.search(txt)
    
        key_line = key_m.group(0) if key_m else None
        ksig_line = ksig_m.group(0) if ksig_m else None

        data.append({
            'path': str(f),
            'tonic': key_line,
            'key_signature': ksig_line
        })
    return pd.DataFrame(data)


key_df = first_matches(ESSEN_ROOT)
#+end_src

#+RESULTS:

#+begin_src python :results output
print(key_df.sample(10))
#+end_src

#+RESULTS:
#+begin_example
                                                path tonic key_signature
4196  data/essen/europa/deutschl/boehme/deut2734.krn  *B-:      *k[b-e-]
6913  data/essen/europa/deutschl/kinder/kindr104.krn   *F:        *k[b-]
3420  data/essen/europa/deutschl/ballad/deut3349.krn   *G:        *k[f#]
7542  data/essen/europa/deutschl/zuccal/deut4985.krn  *B-:      *k[b-e-]
7790           data/essen/europa/italia/italia05.krn   *G:        *k[f#]
8186         data/essen/europa/oesterrh/oestr039.krn   *G:        *k[f#]
6451     data/essen/europa/deutschl/fink/deut208.krn   *F:        *k[b-]
5864     data/essen/europa/deutschl/erk/deut1887.krn   *G:        *k[f#]
5154     data/essen/europa/deutschl/erk/deut1177.krn   *F:        *k[b-]
3675  data/essen/europa/deutschl/ballad/deut3604.krn   *G:        *k[f#]
#+end_example

#+begin_src bash :results output
key data/essen/europa/deutschl/erk/deut1612.krn
#+end_src

#+RESULTS:
: Estimated key: F major	(r=0.8513)	confidence:	33.4%

#+begin_src python :results output
df = pd.merge(df, key_df, on="path")
print(df.sample(5))
#+end_src

#+RESULTS:
:             filename                                         path  region   country  length  melody_id  position pitch duration  is_rest tonic key_signature
: 174689  deut0704.krn  data/essen/europa/deutschl/erk/deut0704.krn  europa  deutschl     132       3415       116     a       16    False   *C:          *k[]
: 383433   han1014.krn        data/essen/asia/china/han/han1014.krn    asia     china      68       7395        53    cc       16    False   *F:        *k[b-]
: 361929   han0988.krn        data/essen/asia/china/han/han0988.krn    asia     china      81       7121        59     d        8    False   *F:        *k[b-]
: 456714  natmn047.krn    data/essen/asia/china/natmin/natmn047.krn    asia     china     220       8368         4    dd       16    False  *B-:      *k[b-e-]
: 292111  lothr057.krn      data/essen/europa/lothring/lothr057.krn  europa  lothring      34       5678        11    dd        8    False   *g:      *k[b-e-]

*** Estimated keys with Humdrum tools
#+begin_src bash :results output
find data/essen -name "*.krn" | while read f; do
    key "$f" | awk -v file="$f" '
        /Estimated key:/ {
            key=$3" "$4
            r=$5
            conf=$7
            print file "," key "," r "," conf
        }'
done > estimated_keys.csv
#+end_src

#+RESULTS:

#+begin_src python :results output
df_keys = pd.read_csv(
  "estimated_keys.csv",
  header=None,
  names=["path", "key", "r", "confidence"]
)

df_keys["r"] = (
    df_keys["r"]
    .str.replace(r"[()r=]", "", regex=True)
    .astype(float)
)

df_keys["confidence"] = (
    df_keys["confidence"]
    .str.replace("%", "")
    .astype(float)
)

print(df_keys.columns)
print(df_keys.head())
#+end_src

#+RESULTS:
: Index(['path', 'key', 'r', 'confidence'], dtype='object')
:                                   path      key       r  confidence
: 0  data/essen/europa/misc/island02.krn  A minor  0.6230        42.6
: 1  data/essen/europa/misc/steier01.krn  G major  0.8366         9.3
: 2   data/essen/europa/misc/norge02.krn  G minor  0.7823        45.3
: 3  data/essen/europa/misc/island01.krn  C major  0.7082        34.9
: 4   data/essen/europa/misc/ellas01.krn  G major  0.4829         6.1

#+begin_src python :results output
df_keys["mode"] = df_keys["key"].str.contains("minor").map(
    {True: "minor", False: "major"}
)

df_keys["tonic"] = (
    df_keys["key"]
    .str.replace(" major", "", regex=False)
    .str.replace(" minor", "", regex=False)
)

df_keys["region"] = df_keys["path"].apply(lambda p: p.split("/")[2])

print(df_keys.head())
#+end_src

#+RESULTS:
:                                   path      key       r  confidence   mode tonic  region
: 0  data/essen/europa/misc/island02.krn  A minor  0.6230        42.6  minor     A  europa
: 1  data/essen/europa/misc/steier01.krn  G major  0.8366         9.3  major     G  europa
: 2   data/essen/europa/misc/norge02.krn  G minor  0.7823        45.3  minor     G  europa
: 3  data/essen/europa/misc/island01.krn  C major  0.7082        34.9  major     C  europa
: 4   data/essen/europa/misc/ellas01.krn  G major  0.4829         6.1  major     G  europa

** Graphs

#+begin_src python :results output
region_counts = Counter()

for f in ESSEN_ROOT.rglob("*.krn"):
    region = f.parts[2] if len(f.parts) > 2 else "unknown"
    region_counts[region] += 1

print(region_counts)
#+end_src

#+RESULTS:
: Counter({'europa': 6213, 'asia': 2246, 'america': 13, 'africa': 1})



#+begin_src python :results file graphics :file melody_lengths.png
files = sorted(ESSEN_ROOT.rglob("*.krn"))
lengths = [len(load_kern_melody(f)) for f in files]

# plt.hist(lengths, bins=50)
# plt.xlabel("Number of events per melody")
# plt.ylabel("Count")
# plt.title("Melody length distribution (Essen corpus)")
# plt.show()


df = pd.DataFrame({"length": lengths})

plt.figure(figsize=(10,7))
sns.histplot(df["length"], bins=50, kde=True)
plt.xlabel("Number of events per melody")
plt.ylabel("Count")
plt.title("Melody length distribution (Essen corpus)")
plt.tight_layout()

plt.savefig("melody_lengths.png")
plt.close()
#+end_src

#+RESULTS:
[[file:melody_lengths.png]]

#+begin_src python :results output
print("median:", np.median(lengths))
print("mean:", np.mean(lengths))
print("max:", max(lengths))
#+end_src

#+RESULTS:
: median: 48.0
: mean: 54.80266729611708
: max: 520

#+begin_src python :results output
pitch_counter = Counter()

for f in files:
  for event in load_kern_melody(f):
    if not event.is_rest:
      pitch_counter[event.pitch] += 1

print("Unique pitches:", len(pitch_counter))
pitch_counter.most_common(20)
#+end_src

#+RESULTS:
: Unique pitches: 114

#+begin_src python :results file graphics :file pitch_freq.png
# plt.figure(figsize=(10,4))
# labels, values = zip(*pitch_counter.most_common(30))
# plt.bar(labels, values)
# # plt.xticks(rotation=90)
# plt.title("Most frequent pitches")
# plt.tight_layout()

# plt.savefig("pitch_common.png")
# plt.close()

df = (
    pd.DataFrame(pitch_counter.items(), columns=["pitch", "count"])
    .sort_values("count", ascending=False)
    .head(30)
)

plt.figure(figsize=(10,6))
sns.barplot(data=df, x="pitch", y="count", palette="viridis")
plt.xticks(rotation=90)
plt.title("Most frequent pitches (top 30)")
plt.tight_layout()

plt.savefig("pitch_freq.png")
plt.close()
#+end_src

#+RESULTS:
[[file:pitch_freq.png]]


#+begin_src python :results file graphics :file rhythm_freq.png
dur_counter = Counter()

for f in files:
    for ev in load_kern_melody(f):
        dur_counter[ev.duration] += 1

df = (
    pd.DataFrame(dur_counter.items(), columns=["duration", "count"])
      .sort_values("count", ascending=False)
      .head(20)
)

plt.figure(figsize=(12, 5))

sns.barplot(
    data=df,
    x="duration",
    y="count",
    palette="viridis"
)

plt.title("Most frequent rhythmic durations (Essen corpus)")
plt.xlabel("Duration (kern reciprocal notation)")
plt.ylabel("Count")
plt.tight_layout()
plt.savefig("rhythm_freq.png", dpi=200)
plt.close()
#+end_src

#+RESULTS:
[[file:rhythm_freq.png]]

#+begin_src python :results file graphics :file rhythm_by_region.png
rows = []

for f in files:
    region = f.parts[2]
    for ev in load_kern_melody(f):
        rows.append((region, ev.duration))

df = pd.DataFrame(rows, columns=["region", "duration"])

plt.figure(figsize=(12,5))
sns.countplot(
    data=df,
    x="duration",
    hue="region",
    order=df["duration"].value_counts().index[:10],
    palette="viridis"
)

plt.figure(figsize=(8,4), dpi=120)
sns.countplot(
    data=df,
    x="duration",
    hue="region",
    order=df["duration"].value_counts().index[:10],
    palette="viridis"
)
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("rhythm_by_region.png", dpi=120, bbox_inches="tight")
plt.close()
#+end_src

#+RESULTS:
[[file:rhythm_by_region.png]]


#+begin_src python :results file graphics :file rhythm_norm_region.png
rows = []

for f in files:
    durations = [ev.duration for ev in load_kern_melody(f)]
    total = len(durations)
    for d in durations:
        rows.append((f.parts[2], d, 1/total))

df = pd.DataFrame(rows, columns=["region", "duration", "weight"])

plt.figure(figsize=(12,5))
sns.barplot(
    data=df,
    x="duration",
    y="weight",
    hue="region",
    estimator=sum,
    palette="viridis"
)

plt.title("Normalized rhythmic distribution per region")
plt.tight_layout()
plt.savefig("rhythm_norm_region.png", dpi=200)
plt.close()
#+end_src

#+RESULTS:
[[file:rhythm_norm_region.png]]
