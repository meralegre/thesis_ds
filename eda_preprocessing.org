#+TITLE: EDA & Preprocessing of Musical Corpus
#+AUTHOR: Maria Gonzalez Alegre
#+DATE: 2025-12-31

#+PROPERTY: header-args:python :session py :results output :exports results :eval yes

* Introduction
* Conclusion
* Manual Preprocessing
** Imports

#+begin_src python :results silent
import pandas as pd
import numpy as np

import re
import zipfile
import pathlib
import random
from typing import List, Optional
from dataclasses import dataclass
#+end_src

** Kern syntax

In the Humdrum syntax, columns of data are called SPINES. SPINES of information may change
position within a file; they may disappear, or split into several columns, for example.

Based on the information found in the Github repo with the Essen files [cite], the music files contain
several indicators that need to be taken into account:

*** INTERPRETATIONS
  Labels that indicate the tyoe of information being represented in each Spine. They are
  represented as two asterisks (**). We also have *SPINE-PATH TERMINATORS*, they indicate the end
  of their respective spine, represented as *-

*** TANDEM INTERPRETATIONS
  Tandem interpretations are identified by a single leading asterisk (*).
  Tandem interpretations encode additional or supplementary information, for example the names
  of the voices

*** COMMENTS
  In any representation, some information may best be conveyed as
  COMMENTS rather than as part of the encoded data. In Humdrum formats they are expressed as
  exclamation marks:
  - *GLOBAL COMMENTS*: they begin with two exclamation marks
  - *LOCAL COMMENTS*: they begin with one exclamation mark
  - *NULL LOCAL COMMENTS*: exclamation marks with no text

*** PITCH
  Enconded through a scheme of upper and lower case letters:
  - c      middle C (i.e. C4)
  - cc     C an octave higher than middle C (C5)
  - C      C an octave lower than middle C (C3)
  - CC     C two octaves lower than middle C (C2)
  - B      B below middle C (B3)
  - b      B a major seventh above middle C (B4)
  - d#     D-sharp above middle C (D#4)
  - d##    D double-sharp above middle C
  - d###   D tiple-sharp above middle C
  - e-     E-flat above middle C (enharmonically equivalent to d##)
  - BB--   B double-flat; augmented ninth below middle C
  - cn     C natural, middle C

  Sharps, flats, and naturals are mutually exclusive in **kern, so tokens such as "cc#n" and
  "GG-#" are illegal. Something to take into account when cleaning the data, in case some errors
  are present.

*** SLURS, TIES, PHRASES
  - *Phrases*: indicated by {}
  - *Slurs*: indicated by () --> ligadura entre notas distintas
  - *Ties*: indicated by [] --> ligadura entre misma nota

  They can be nested and elided (the overlapping of phrases, where the last note or chord
  of one phrase serves simultaneously as the first note or chord of the next)

*** ORNAMENTS
  - "T" and "t": whole-tone and semitone TRILLS
  - "M" and "m": whole-tone and semitone MORDENTS
  - "W" and "w": whole-tone and semitone INVERTED MORDENTS
  - "S":  a TURN
  - dollar sign ("$"): an inverted (or Wagnerian) TURN
  - "R":  When a concluding turn is appended to the end of an ornament, "R" is
    added to the ornament signifier (as in "tR" and "TR").
  - ":" (multi-note) ARPEGGIATION
  - "0": presence of ornaments OTHER than trills, mordents, inverted mordents, and turns.

*** ARTICULATION MARKS
  - (') for STACCATO
  - double-quote (") for PIZZICATO
  - greve (`) for ATTACCA
  - tilde (~) for TENUTO
  - caret (^) for all note-related accents (including < and >)

*** UP & DOWN BOWS
  - up-bow (v) and down-bow (u)

*** STEMS (plica)
  - "/": Up-stem
  - "\": Down-stem

*** DURATIONS
  0       breve duration (redonda)
  1       whole duration
  2       half duration
  4       quarter duration
  8       eighth duration
  16      sixteenth duration
  32      thirty-second duration
  64      sixty-fourth duration

  *Dotted notes*:
    2.	dotted half duration
    8..	doubly-dotted eighth duration

  The semicolon (;) denotes a pause.

*** GRACE NOTES & GROUPETTOS
  - *ACCIACCATURAS*: "q", e.g "G#q"
  - *GROUPETTOS*: "Q", e.g minature sixteenth-note middle C would be encoded as "16cQ"
  - *APPOGGIATURAS*: The appoggiatura note itself is designated by the upper-case letter "P", whereas
    the subsequent note (whose notated duration has been shorted) is designated by the
    lower-case letter "p".

*** BEAMING
  - beginning and ends of beams are signified by the upper-case letters
    "L" and "J" respectively
  - Partial beams may extend to the right (K) or left (k)
  - each beam is designated by its own L-J pair, e.g:
    16..LL
    64JJkk
 
*** BARLINES
   0-9	measure numbers
   a-z	alternate measures
   ;	pause
   =	barline
   ==	double barline
   |	normal width visual rendering
   !	heavy width visual rendering
   '	partial barline (from second to fourth line)
   `	partial barline (short stroke at top of staff)
   -	invisible barline
   :	repeat sign

**** Examples
     =	        unnumbered barline
     =29 	the beginning of measure 29
     =29; 	the beginning of measure 29 with pause
     =29a	first occurrence of measure 29
     =29c	third occurrence of measure 29
     =29c;	third occurrence of measure 29 with pause
     ==	        double barline
     ==;	double barline with pause
     =|	        unnumbered barline, normal line width
     =!	        unnumbered barline, heavy line width
     ==|!	double barline, normal line followed by heavy line
     =29|	beginning of measure 29, normal line width
     =:|:	barline with left and right repeats, normal line width
     =:||:	barline with left and right repeats, two normal-width lines
     ='	        unnumbered barline, rendered with partial barline (mid)
     =29`	beginning of measure 29, rendered with partial barline (top)
     =29-	beginning of measure 29, no barline drawn
     ==:|!	double barline with repeat, normal/heavy lines
     ==|	logical double barline, visually rendered as single normal line
     |	        not a barline
     29|	not a barline

*** TABLE OF SIGNIFIERS
	0       breve duration
	1       whole duration
	2       half duration
	3       half-note triplet duration
	4       quarter duration
	6       quarter-note triplet duration
	8       eighth duration
	12      eighth-note triplet duration
	16      sixteenth duration
	24      sixteenth-note triplet duration
	32      thirty-second duration
	64      sixty-fourth duration
	128     one-hundred and twenty-eighth duration
	.       duration augmentation dot (must follow a number)
	-       flat sign (minus character)
	--      double-flat (two successive minus characters)
	a-g     absolute pitches above middle C
	A-G     absolute pitches below middle C
	#       sharp
	##      double sharp
	h       end glissando
	j       harmonic
	k       partial beam extending leftward
	kk      two partial beams extending leftward
	m       mordent (semitone)
	n       natural sign
	p       designator of a note subsequent to an appoggiatura
	q       acciaccatura (grace note signifier; in lieu of duration)
	r       rest
	t       trill (semitone)
	u       down-bow
	v       up-bow
	w       inverted mordent (semitone)
	x       editorial interpretation; immediately preceding signifier is
                  interpreted
	xx      editorial interpretation; entire data token is interpreted
	y       editorial mark:  invisible symbol; unprinted note-, rest-, or
	          barline-attribute, but logically implied
	yy      editorial mark:  invisible symbol; unprinted note, rest, or
	          barline, but logically implied
	z       sforzando
	H       begin glissando
	I       generic articulation (unspecified articulation)
	J       end beam
	JJ      end two beams
	K       partial beam extending rightward
	KK      two partial beams extending rightward
	L       start beam
	LL      start two beams
	M       mordent (whole tone)
	O       generic ornament (unspecified ornament)
	P       appoggiatura note designator
	Q       groupetto note designator
	R       signified ornament ends with a turn
	S       turn
	$       Wagnerian turn
	T       trill (whole tone)
	W       inverted mordent (whole tone)
	X       editorial intervention; immediately preceding signifier is an
	          editorial addition
	XX      editorial intervention; entire data token is an editorial
                  addition
	Y       editorial mark:  sic marking; information is encoded
	          literally, but is questionable
	YY      editorial mark:  sic marking; entire data token is encoded
	          literally, but is questionable
	<space> (space character) multiple-stop conjunction -- indicates
	        joint note-tokens
	=       barline; == double barline
	[       first note of a tie
	]       last note of a tie
	_       middle note(s) of a tie (underscore)
	(       slur start
	)       slur end
	{       phrase mark (start)
	}       phrase mark (end)
	;       pause sign
	'       staccato mark
	s       spiccato
	"       pizzicato mark
	`       attacca mark
	~       tenuto mark
	^       accent mark
	:       arpeggiation (of multi-note chord)
	,       breath mark
	/       up-stem
	\       down-stem
	&       elision marker (for slurs or phrases)
	?       editorial mark: immediately preceding signifier has accompanying
	          editorial footnote
	??      editorial mark: entire preceding data token has accompanying
	          editorial footnote

*** SUMMARY

| signified                           | signifier(s)        | comments                     |
|-------------------------------------+---------------------+------------------------------|
| 1. open phrase elision indicator    | &                   | must precede {               |
| 2. open phrase mark                 | {                   |                              |
| 3. open slur elision indicator      | &                   | must precede (               |
| 4. open slur                        | (                   |                              |
| 5. open tie                         | [                   |                              |
| 6. duration                         | 0123456789          | any combination; signifiers  |
| may be repeated                     |                     |                              |
| 7. augmentation dot(s)              | .                   | signifier may be repeated    |
| 8. pitch                            | abcdefgABCDEFG      | only one of; signifier may   |
| be repeated                         |                     |                              |
| 9. accidental                       | - or # or n         | - and # may be repeated      |
| 10. pause                           | ;                   |                              |
| 11. ornament                        | MmS$TtWwR or O      | O precludes others; no repe- |
| tition of a given signifier;        |                     |                              |
| must appear in order given          |                     |                              |
| 12. appoggiatura designator         | p or P              |                              |
| 13. acciaccatura designator         | q                   |                              |
| 14. groupetto designator            | Q                   |                              |
| 15. articulation                    | z ' " ` ~ ^ : or I  | I precludes others; no re-   |
| petition of a given signifier;      |                     |                              |
| must appear in order given          |                     |                              |
| 16. bowing                          | u or v              | only one of                  |
| 17. stem-direction                  | / or \              | only one of                  |
| 18. beaming                         | L or J              | signifiers may be repeated   |
| 19. partial beaming                 | k or K              | signifiers may be repeated   |
| 20. user-defined marks              | il                  | one or more of;              |
| NUVZ                                | may be repeated but |                              |
| @ % +                               | < >                 | must be in order given       |
| 21. closed or continuing tie        | ] or _              |                              |
| 22. closed slur elision indicator   | &                   | must precede )               |
| 23. closed slur                     | )                   |                              |
| 24. closed phrase elision indicator | &                   | must precede }               |
| 25. closed phrase mark              | }                   |                              |
| 26. breath mark                     | ,                   |                              |
| 27. editorial marks                 | xx or XX            |                              |
| 28. editorial marks                 | yy or YY            |                              |
| 29. editorial marks                 | ??                  |                              |
|                                     |                     |                              |

** Essen Folksongs Data

#+begin_src python :results silent
ESSEN_ROOT = pathlib.Path("data/essen")

ESSEN_REGIONS = ["europa", "asia", "africa", "america"]
#+end_src

** Parsing decisions and functions
<<sec:parsing>>
According to the =**kern= specification, each token consists of a combination of signifiers
encoding duration, pitch, accidentals, rests, ornaments, articulation, beaming, editorial
marks, and other information.

For the purpose of melodic expectation modeling, we define *musical events* as
notes and rests with the following properties:

- *Kept information*:
  - Duration digits and dots (=0–9= and =.=).
  - Pitch letters (=a–g= / =A–G=) and accidentals (_ =, =-=, =#=, =n=).
  - Rest marker =r= (and potentially pause =;=) to represent silence.

- *Removed information*:
  - Ornaments (trills, mordents, turns, etc.).
  - Appoggiaturas, acciaccaturas (grace notes), and groupettos.
  - Articulation, bowing, stem direction, beaming, partial beaming.
  - User-defined and editorial marks.

This follows the manual’s distinction between core syntactic information and
decorative or editorial notation and matches common practice in IDyOM-style
melodic modeling where durationless ornaments and purely notational details
are excluded from the event stream.

#TODO:
GROUPING_CHARS: 

*** Elements definitions
#+begin_src python :results silent
# Core signifier sets
DURATION_CHARS = set("0123456789.")
PITCH_CHARS = set("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ")
ACCIDENTAL_CHARS = set("_-#n")
REST_CHAR = "r"
PAUSE_CHAR = ";"
GROUPING_CHARS = set("{}()[]")

# Non-core signifiers (to be removed)
ORNAMENT_CHARS = set("Mm$STtwWRO")     # ornaments
APPOGGIATURA_CHARS = set("pP")          # appoggiaturas
GRACE_CHAR = "q"                        # acciaccaturas
GROUPETTO_CHAR = "Q"                    # groupettos
ARTICULATION_CHARS = set("z'\"`^~:I")   # articulations
BOWING_CHARS = set("uv")                # bowing positions
STEM_DIR_CHARS = set("/\\")             # stem direction
BEAM_CHARS = set("LJ")                  # beaming
PARTIAL_BEAM_CHARS = set("kK")          # partial beaming
EDITORIAL_CHARS = set("xXyY?")          # editorial marks
USER_MARK_CHARS = set("iltNUVZ@%+")     # user-defined marks

NON_CORE_CHARS = (
    ORNAMENT_CHARS
    | APPOGGIATURA_CHARS
    | ARTICULATION_CHARS
    | BOWING_CHARS
    | STEM_DIR_CHARS
    | BEAM_CHARS
    | PARTIAL_BEAM_CHARS
    | EDITORIAL_CHARS
    | USER_MARK_CHARS
)
#+end_src

*** Helper functions
<<sec:helper>>
Above we defined which elements and characters are core for the analysis and processing
of data in order to prepare it for modelling. In this section we will define helper functions
to recognise said characters and clean the =**kern= files to prepare them for EDA and modelling.

Instead of directly defining a helper function for each unnecessary element in the data, we
just focus for now on null tokens and durationless ornaments that were defined previously to
avoid overcrowding later on the full cleaning function. Elements such as interpretations,
tandems and comments are easily included in the bigger function, having small helper functions
would be a good addition but it is not necessary for such small elements.

Since these do not represent musical events, we do not need to include them in the process.
Better skip them now to avoid unnecessary elements in the data.

Even though for a more detailed and elaborate study of the musical data elements such as
acciaturas and groupettos might be useful and interesting, we will opt to remove them for now.
In case we want to work with their inclusion later on, we can simply rerun the cleaning of
the data without the removal of these characters.

#+begin_src python :results silent
def is_null_token(line):
  return line.startswith(".")

def has_grace_or_groupetto(tok: str) -> bool:
  # Durationless ornaments that should not be counted as events.
  return (GRACE_CHAR in tok) or (GROUPETTO_CHAR in tok)
#+end_src

We will stript all ornaments, bowing, stems, beamings and editorial marks as well to leave only
the minimal syntactic information needed to define duration and pitch (including rests).
This way we focus on structural melodic content rather than detailed notations. 

#+begin_src python :results silent
def strip_non_core_signifiers(tok: str) -> str:
    """
    Remove ornaments, articulation, beams, editorial marks and other
    non-core signifiers, preserving duration, pitch, accidentals and rest.
    """
    return "".join(ch for ch in tok if ch not in NON_CORE_CHARS)
#+end_src

*** Parsing tokens

The =parse_kern_token= function is the main function for the parsing process.
It gathers the previous helper functions defined above in order to create a single
=**kern= token into KernEvents.
Why do we create a class for this?
- We want to turn messy tokens into a structured, clean and homogenous event that will make it easier
  to analyse and feed the models later on.

In this section, we focus on the cleaning of the data. Ornaments and editorial notations are not
necesary for our purpose and will just end up creating noise for the ultimate modelling section. 

#+begin_src python :results output
@dataclass
class KernEvent:
    duration: str
    pitch: str
    is_rest: bool


def parse_kern_token(tok: str) -> Optional[KernEvent]:
    tok = tok.strip()
    if not tok or is_null_token(tok):
        return None
    if has_grace_or_groupetto(tok):
        return None

    tok = strip_non_core_signifiers(tok)

    # strip grouping / phrasing markers that can wrap tokens
    while tok and tok[0] in GROUPING_CHARS:
        tok = tok[1:]
    while tok and tok[-1] in GROUPING_CHARS:
        tok = tok[:-1]
    if not tok or is_null_token(tok):
        return None

    # Extract duration (leading digits + dots)
    i = 0
    dur_chars = []
    while i < len(tok) and tok[i].isdigit():
        dur_chars.append(tok[i])
        i += 1
    while i < len(tok) and tok[i] == ".":
        dur_chars.append(tok[i])
        i += 1
    duration = "".join(dur_chars)
    if not duration:
        return None

    pitch_part = tok[i:]
    if not pitch_part:
        return None

    is_rest = (REST_CHAR in pitch_part) or (PAUSE_CHAR in pitch_part)
    if is_rest:
        pitch_norm = "r"
    else:
        pitch_chars = [ch for ch in pitch_part if ch in PITCH_CHARS or ch in ACCIDENTAL_CHARS]
        if not pitch_chars:
            return None
        pitch_norm = "".join(pitch_chars)

    return KernEvent(duration=duration, pitch=pitch_norm, is_rest=is_rest)

#+end_src

#+RESULTS:

**** Example

#+BEGIN_SRC python :results output
# Some example **kern note tokens, including ornaments and rests.
tokens = [
    "4c",          # quarter-note C
    "8g#",         # eighth-note G sharp
    "4cL",         # quarter-note C with beaming (L) that should be stripped
    "16bq",        # grace-note B (q) that should be discarded entirely
    "8.cc#",       # dotted eighth-note C-sharp
    "4r",          # quarter rest
    "4G$'",        # quarter-note G with ornament ($) and articulation (') to drop
    ".",
]

for tok in tokens:
    ev = parse_kern_token(tok)
    print(f"token={tok!r} ->", ev)
#+END_SRC

#+RESULTS:
: token='4c' -> KernEvent(duration='4', pitch='c', is_rest=False)
: token='8g#' -> KernEvent(duration='8', pitch='g#', is_rest=False)
: token='4cL' -> KernEvent(duration='4', pitch='c', is_rest=False)
: token='16bq' -> None
: token='8.cc#' -> KernEvent(duration='8.', pitch='cc#', is_rest=False)
: token='4r' -> KernEvent(duration='4', pitch='r', is_rest=True)
: token="4G$'" -> KernEvent(duration='4', pitch='G', is_rest=False)
: token='.' -> None

** Loading and cleaning the Essen corpus
This section walks the Essen folder structure (grouped by country/region),
parses each file using the token‑level rules above, and filters out very short
melodies. The result is a list of cleaned event sequences with metadata.

We loop over each region found in the Essen data folder. For each folder we recursively
find all Humdrum =**kern= files. After obtaining the files, we derive a simple
contry label from the path by taking the second element of the relative path. This way
we can group the results based on the countries and regions. 

#+begin_src python :results silent
def iter_essen_files():
    """
    Yield (path,) for every .krn file anywhere under data/essen.
    """
    for path in ESSEN_ROOT.rglob("*.krn"):
        yield path
#+end_src

#+begin_src python :results output
files_seen = list(iter_essen_files())
print("Files seen:", len(files_seen))
#+end_src

#+RESULTS:
: Files seen: 8473

#+begin_src python :results output
for i, p in enumerate(iter_essen_files()):
    print(i, "->", p)
    if i == 9:
        break
#+end_src

#+RESULTS:
#+begin_example
0 -> data/essen/europa/misc/island02.krn
1 -> data/essen/europa/misc/steier01.krn
2 -> data/essen/europa/misc/norge02.krn
3 -> data/essen/europa/misc/island01.krn
4 -> data/essen/europa/misc/ellas01.krn
5 -> data/essen/europa/misc/steier03.krn
6 -> data/essen/europa/misc/steier02.krn
7 -> data/essen/europa/misc/norge01.krn
8 -> data/essen/europa/misc/steier06.krn
9 -> data/essen/europa/misc/emmenth1.krn
#+end_example


After obtaining the =**kern= files, we need to extract from the full file the musical
representations that we need for future training as explained in the [[sec:parsing][parsing section]]
and the [[sec:helper][helper functions]] definition.
This way, we apply the classification rules from the Humdrum spec:
We skip empty lines and the following attributes:
- global and local comments
- interpretation lines that declare spyne types
- tandem interpretations (e.g., name of voices)
- barlines

With this function we apply the cleaning previously defined with =parse_kern_tokens= on
the full Humdrum file. 

For the remaining lines, we split the data on tab and take the first token, assuming monophonic
melodies and one relevant spine per file (which is how Essen is structured for melodic analysis)

#+begin_src python :results output
def load_kern_melody(path: pathlib.Path):
    out = []
    raw_tokens = 0
    parsed_tokens = 0

    with path.open("r", encoding="utf-8", errors="ignore") as f:
        for raw in f:
            line = raw.strip()
            if not line:
                continue

            if line.startswith(("*", "!", "=", ".")):
                continue

            tok = line.split("\t")[0].strip()
            raw_tokens += 1

            ev = parse_kern_token(tok)
            if ev is not None:
                out.append(ev)
                parsed_tokens += 1

    return out

test_path = pathlib.Path("data/essen/europa/misc/island02.krn")
events = load_kern_melody(test_path)
print("EVENTS:", len(events))
for i, ev in enumerate(events[:10]):
    print(i, ev)
#+end_src

#+RESULTS:
#+begin_example
EVENTS: 48
0 KernEvent(duration='8.', pitch='a', is_rest=False)
1 KernEvent(duration='16', pitch='b', is_rest=False)
2 KernEvent(duration='8', pitch='ccn', is_rest=False)
3 KernEvent(duration='8.', pitch='b', is_rest=False)
4 KernEvent(duration='16', pitch='a', is_rest=False)
5 KernEvent(duration='8', pitch='g#', is_rest=False)
6 KernEvent(duration='8.', pitch='a', is_rest=False)
7 KernEvent(duration='16', pitch='b', is_rest=False)
8 KernEvent(duration='8', pitch='ccn', is_rest=False)
9 KernEvent(duration='4', pitch='b', is_rest=False)
#+end_example


#+begin_src python :results silent
MIN_EVENTS = 20

def collect_clean_essen():
    melodies = []
    meta_list = []

    for path in ESSEN_ROOT.rglob("*.krn"):
        events = load_kern_melody(path)
        # if len(events) < MIN_EVENTS:
        #     continue

        # derive region/country from relative path
        rel_parts = path.relative_to(ESSEN_ROOT).parts
        region = rel_parts[0] if len(rel_parts) > 0 else "unknown"
        country = rel_parts[1] if len(rel_parts) > 1 else "unknown"

        melodies.append(events)
        meta_list.append({
            "filename": path.name,
            "path": str(path),
            "region": region,
            "country": country,
            "length": len(events),
        })
    return melodies, meta_list
#+end_src

#+begin_src python :results output
melodies, meta = collect_clean_essen()
print("Number of melodies:", len(melodies))
#+end_src

#+RESULTS:
: Number of melodies: 8473

Let's inspect some of the melodies
#+begin_src python :results output
idxs = random.sample(range(len(meta)), 20)
for i in idxs:
    print(i, meta[i]["region"], meta[i]["country"], meta[i]["filename"], "len:", meta[i]["length"])
#+end_src

#+RESULTS:
#+begin_example
7779 asia china han0894.krn len: 56
1704 europa deutschl deut2790.krn len: 56
7774 asia china han0670.krn len: 63
1643 europa deutschl deut2350.krn len: 72
6349 asia china shanx606.krn len: 46
5536 europa schweiz suisse62.krn len: 40
7376 asia china han0083.krn len: 77
1331 europa deutschl deut2922.krn len: 62
7816 asia china han0077.krn len: 32
3825 europa deutschl deut1348.krn len: 44
8143 asia china han0399.krn len: 40
7284 asia china han0030.krn len: 51
756 europa deutschl deut3601.krn len: 25
5781 europa nederlan neder022.krn len: 49
6895 asia china shanx352.krn len: 35
3876 europa deutschl deut0679.krn len: 35
7426 asia china han0337.krn len: 107
7280 asia china han0781.krn len: 97
7416 asia china han0653.krn len: 79
7899 asia china han0528.krn len: 86
#+end_example

#+begin_src python :results output
m0 = melodies[0]
print("First melody: length", len(m0))
print("First 10 events:")
for i, ev in enumerate(m0[:10]):
    print(i, ev)
#+end_src

#+RESULTS:
#+begin_example
First melody: length 48
First 10 events:
0 KernEvent(duration='8.', pitch='a', is_rest=False)
1 KernEvent(duration='16', pitch='b', is_rest=False)
2 KernEvent(duration='8', pitch='ccn', is_rest=False)
3 KernEvent(duration='8.', pitch='b', is_rest=False)
4 KernEvent(duration='16', pitch='a', is_rest=False)
5 KernEvent(duration='8', pitch='g#', is_rest=False)
6 KernEvent(duration='8.', pitch='a', is_rest=False)
7 KernEvent(duration='16', pitch='b', is_rest=False)
8 KernEvent(duration='8', pitch='ccn', is_rest=False)
9 KernEvent(duration='4', pitch='b', is_rest=False)
#+end_example

#+begin_src python :results output
# Explode: one row per KernEvent
events_df = []
for i, (events, m) in enumerate(zip(melodies, meta)):
    for j, ev in enumerate(events):
        row = m.copy()
        row.update({
            'melody_id': i,
            'position': j,
            'pitch': ev.pitch,
            'duration': ev.duration,
            'is_rest': ev.is_rest
        })
        events_df.append(row)

df = pd.DataFrame(events_df)
print(df.shape)
print(df.sample(5))
#+end_src

#+RESULTS:
: (464343, 10)
:             filename                                         path  region   country  length  melody_id  position pitch duration  is_rest
: 423058   han0064.krn        data/essen/asia/china/han/han0064.krn    asia     china      34       7895         5     a       16    False
: 201299  deut2079.krn  data/essen/europa/deutschl/erk/deut2079.krn  europa  deutschl      41       3980        25     f        2    False
: 347650  shanx231.krn    data/essen/asia/china/shanxi/shanx231.krn    asia     china      45       6860         3    ff        4    False
: 261174   deut170.krn  data/essen/europa/deutschl/fink/deut170.krn  europa  deutschl      61       5085        30     r        8     True
: 237665   deut355.krn  data/essen/europa/deutschl/fink/deut355.krn  europa  deutschl     104       4707        51   ee-       4.    False

* Humdrum Tools
** Extracting and cleaning melodies
#+begin_src bash :results output
rid -GLI data/essen/europa/misc/island02.krn \
  | awk -F'\t' '{print $1}' \
  | grep -v '^=' \
  > /tmp/island02.tokens

head -n 20 /tmp/island02.tokens
#+end_src

#+RESULTS:
#+begin_example
{8.a
16b
8ccn
8.b
16a
8g#
8.a
16b
8ccn
4b
8r}
{4b
8b
4ccn
8dd
4.ee
4dd
8r}
{4ccn
8ccn
#+end_example

* EDA
** Melody inspection

#+begin_src bash :results output
find data/essen -name "*.krn" | while read f; do
  grep -m 1 '^\*\*' "$f" | awk -F'\t' '{print NF}'
done | sort | uniq -c
#+end_src

#+RESULTS:
: 8473 1

#+begin_src python :results output
from pathlib import Path

voice_counts = {}

for f in Path("data/essen").rglob("*.krn"):
    with f.open(encoding="utf-8", errors="ignore") as fh:
        for line in fh:
            if line.startswith("**"):
                n_voices = line.count("\t") + 1
                voice_counts[n_voices] = voice_counts.get(n_voices, 0) + 1
                break

for k in sorted(voice_counts):
    print(f"{k} voices: {voice_counts[k]} files")
#+end_src

#+RESULTS:
: 1 voices: 8473 files

** Obtaining keys

#+begin_src bash :results output
key data/essen/europa/misc/island02.krn
#+end_src

#+RESULTS:
: Estimated key: A minor	(r=0.6230)	confidence:	42.6%

#+begin_src bash :results output
mkeyscape -ln data/essen/europa/misc/island02.krn | magick - ./island02_key.png
#+end_src

#+RESULTS:

#+begin_src python :results output
key_tandem_re = re.compile(r'^\*[A-Ga-g](?:#|-)?\s*:\s*$', re.M)
ksig_re = re.compile(r'^\*k\[[^\]]*\]\s*$', re.M)

def first_matches(path: Path=ESSEN_ROOT):
    files = sorted(path.rglob("*.krn"))
    data = []
    for f in files:
        txt = f.read_text(encoding="utf-8", errors="ignore")
        key_m = key_tandem_re.search(txt)
        ksig_m = ksig_re.search(txt)
    
        key_line = key_m.group(0) if key_m else None
        ksig_line = ksig_m.group(0) if ksig_m else None

        data.append({
            'path': str(f),
            'tonic': key_line,
            'key_signature': ksig_line
        })
    return pd.DataFrame(data)


key_df = first_matches(ESSEN_ROOT)
#+end_src

#+RESULTS:


#+begin_src python :results output
print(key_df.sample(10))
#+end_src

#+RESULTS:
#+begin_example
                                                 path tonic key_signature
8274            data/essen/europa/polska/polska23.krn   *G:        *k[f#]
4428   data/essen/europa/deutschl/boehme/deut2966.krn   *F:        *k[b-]
5589      data/essen/europa/deutschl/erk/deut1612.krn   *F:        *k[b-]
944             data/essen/asia/china/han/han0869.krn   *G:        *k[f#]
8291           data/essen/europa/romania/romani15.krn   *F:        *k[b-]
3765   data/essen/europa/deutschl/boehme/deut2303.krn  *E-:    *k[b-e-a-]
2650  data/essen/europa/deutschl/altdeu1/deut4001.krn   *F:        *k[b-]
7201   data/essen/europa/deutschl/zuccal/deut4644.krn   *C:          *k[]
6490      data/essen/europa/deutschl/fink/deut247.krn   *D:      *k[f#c#]
4507      data/essen/europa/deutschl/dva/deut4467.krn   *G:        *k[f#]
#+end_example

#+begin_src python :results output
print(key_df.dtypes)
target_path = "data/essen/europa/polska/polska23.krn"
row = key_df[key_df['path'] == target_path]
print(row)
#+end_src

#+RESULTS:
: path             object
: tonic            object
: key_signature    object
: dtype: object
:                                        path tonic key_signature
: 8274  data/essen/europa/polska/polska23.krn   *G:        *k[f#]

#+begin_src bash :results output
key data/essen/europa/polska/polska23.krn
#+end_src

#+RESULTS:
: Estimated key: G major	(r=0.8116)	confidence:	14.0%
